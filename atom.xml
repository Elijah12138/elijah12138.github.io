<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Elijah的个人博客</title>
  
  
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://yoursite.com/"/>
  <updated>2020-04-20T12:15:23.238Z</updated>
  <id>http://yoursite.com/</id>
  
  <author>
    <name>Elijah</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>pytorch-使用AlexNet完成模型的训练，微调</title>
    <link href="http://yoursite.com/2020/04/17/pytorch-%E4%BD%BF%E7%94%A8AlexNet%E5%AE%8C%E6%88%90%E6%A8%A1%E5%9E%8B%E7%9A%84%E8%AE%AD%E7%BB%83%EF%BC%8C%E5%BE%AE%E8%B0%83/"/>
    <id>http://yoursite.com/2020/04/17/pytorch-%E4%BD%BF%E7%94%A8AlexNet%E5%AE%8C%E6%88%90%E6%A8%A1%E5%9E%8B%E7%9A%84%E8%AE%AD%E7%BB%83%EF%BC%8C%E5%BE%AE%E8%B0%83/</id>
    <published>2020-04-16T16:00:00.000Z</published>
    <updated>2020-04-20T12:15:23.238Z</updated>
    
    <content type="html"><![CDATA[<h3 id="1-AlexNet的网络结构"><a href="#1-AlexNet的网络结构" class="headerlink" title="1. AlexNet的网络结构"></a>1. AlexNet的网络结构</h3><p><img src="http://blog-elijah.test.upcdn.net/elijah/pytorch-AlexNet.png" alt="AlexNet"></p><p>AlexNet总共包含8层变换，分别为5层卷积层、2个全连接层和一个全连接输出层</p><ol><li>第一层卷积窗口的形状为11*11</li><li>第二层卷积窗口的形状缩减为5*5</li><li>第三层到第五层卷积窗口均为3*3</li><li>第六层全连接层输入为256<em>5</em>5，输出为4096，激活函数采用了ReLu</li><li>第七层全连接层输入为4096，输出为4096，激活函数采用了ReLu</li><li>由于原模型是使用imagenet数据集进行训练的，所以输出为1000</li></ol><h3 id="2-代码实现"><a href="#2-代码实现" class="headerlink" title="2. 代码实现"></a>2. 代码实现</h3><h4 id="2-1-导入相应的包"><a href="#2-1-导入相应的包" class="headerlink" title="2.1 导入相应的包"></a>2.1 导入相应的包</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> time</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> nn, optim</span><br><span class="line"><span class="keyword">import</span> torchvision</span><br><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"><span class="comment"># 如果有gpu计算设备，选择gpu计算设备，否则选择在cpu上训练</span></span><br><span class="line">device = torch.device(<span class="string">'cuda'</span> <span class="keyword">if</span> torch.cuda.is_available() <span class="keyword">else</span> <span class="string">'cpu'</span>)</span><br><span class="line">device</span><br></pre></td></tr></table></figure><h4 id="2-2-定义模型"><a href="#2-2-定义模型" class="headerlink" title="2.2 定义模型"></a>2.2 定义模型</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">AlexNet</span><span class="params">(nn.Module)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self)</span>:</span></span><br><span class="line">        super(AlexNet, self).__init__()</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 卷积层</span></span><br><span class="line">        self.conv = nn.Sequential(</span><br><span class="line">            <span class="comment"># 第一层卷积</span></span><br><span class="line"><span class="comment"># 如果使用mnist类的数据集，输入通道为1，如果使用的cifar等彩色图像的数据集，输入通道为3</span></span><br><span class="line">            nn.Conv2d(<span class="number">3</span>, <span class="number">96</span>, <span class="number">11</span>, <span class="number">4</span>),</span><br><span class="line">            nn.ReLU(),</span><br><span class="line">            nn.MaxPool2d(<span class="number">3</span>, <span class="number">2</span>),</span><br><span class="line">            </span><br><span class="line">            <span class="comment"># 第二层卷积，开始减小卷积窗口</span></span><br><span class="line">            nn.Conv2d(<span class="number">96</span>, <span class="number">256</span>, <span class="number">5</span>, <span class="number">1</span>, <span class="number">2</span>),</span><br><span class="line">            nn.ReLU(),</span><br><span class="line">            nn.MaxPool2d(<span class="number">3</span>, <span class="number">2</span>),</span><br><span class="line">            </span><br><span class="line">            <span class="comment"># 第三层卷积</span></span><br><span class="line">            nn.Conv2d(<span class="number">256</span>, <span class="number">384</span>, <span class="number">3</span>, <span class="number">1</span>, <span class="number">1</span>),</span><br><span class="line">            nn.ReLU(),</span><br><span class="line">            </span><br><span class="line">            <span class="comment"># 第四层卷积</span></span><br><span class="line">            nn.Conv2d(<span class="number">384</span>, <span class="number">384</span>, <span class="number">3</span>, <span class="number">1</span>, <span class="number">1</span>),</span><br><span class="line">            nn.ReLU(),</span><br><span class="line">            </span><br><span class="line">            <span class="comment"># 第五层卷积</span></span><br><span class="line">            nn.Conv2d(<span class="number">384</span>, <span class="number">256</span>, <span class="number">3</span>, <span class="number">1</span>, <span class="number">1</span>),</span><br><span class="line">            nn.ReLU(),</span><br><span class="line">            nn.MaxPool2d(<span class="number">3</span>, <span class="number">2</span>)</span><br><span class="line">        )</span><br><span class="line">        </span><br><span class="line">        self.fc = nn.Sequential(</span><br><span class="line">            <span class="comment"># 第一层全连接层</span></span><br><span class="line">            nn.Linear(<span class="number">256</span>*<span class="number">5</span>*<span class="number">5</span>, <span class="number">4096</span>),</span><br><span class="line">            nn.ReLU(),</span><br><span class="line">            nn.Dropout(<span class="number">0.5</span>),</span><br><span class="line">            </span><br><span class="line">            <span class="comment"># 第二层全连接层</span></span><br><span class="line">            nn.Linear(<span class="number">4096</span>, <span class="number">4096</span>),</span><br><span class="line">            nn.ReLU(),</span><br><span class="line">            nn.Dropout(<span class="number">0.5</span>),</span><br><span class="line">            </span><br><span class="line">            <span class="comment"># 第三层全连接层（输出层）</span></span><br><span class="line">            nn.Linear(<span class="number">4096</span>, <span class="number">10</span>)</span><br><span class="line">        )</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, x)</span>:</span></span><br><span class="line">        x = self.conv(x)</span><br><span class="line">        x = self.fc(x.view(x.shape[<span class="number">0</span>], <span class="number">-1</span>))</span><br><span class="line">        <span class="keyword">return</span> x</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">alexnet = AlexNet()</span><br><span class="line">alexnet</span><br></pre></td></tr></table></figure><h4 id="2-3-加载数据"><a href="#2-3-加载数据" class="headerlink" title="2.3 加载数据"></a>2.3 加载数据</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">load_data</span><span class="params">(batch_size, resize=None, root=<span class="string">'./data/CIFAR10'</span>)</span>:</span></span><br><span class="line">    trans = []</span><br><span class="line">    <span class="keyword">if</span> resize:</span><br><span class="line">        trans.append(torchvision.transforms.Resize(size=resize))</span><br><span class="line">    trans.append(torchvision.transforms.ToTensor())</span><br><span class="line">    </span><br><span class="line">    transform = torchvision.transforms.Compose(trans)</span><br><span class="line"></span><br><span class="line"><span class="comment"># torchvision.datasets包内还有许多其他的数据集，只需要修改网络的输入通道数和输出类别数即可</span></span><br><span class="line">    data_train = torchvision.datasets.CIFAR10(root=root, train=<span class="literal">True</span>, download=<span class="literal">True</span>, transform=transform)</span><br><span class="line">    data_test = torchvision.datasets.CIFAR10(root=root, train=<span class="literal">False</span>, download=<span class="literal">True</span>, transform=transform)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">if</span> sys.platform.startswith(<span class="string">'win'</span>):</span><br><span class="line">        num_workers = <span class="number">0</span>  <span class="comment"># 0表示不用额外的进程来加速读取数据</span></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        num_workers = <span class="number">4</span></span><br><span class="line">    </span><br><span class="line">    train_iter = torch.utils.data.DataLoader(data_train, batch_size=batch_size, shuffle=<span class="literal">True</span>, num_workers=num_workers)</span><br><span class="line">    test_iter = torch.utils.data.DataLoader(data_test, batch_size=batch_size, shuffle=<span class="literal">False</span>, num_workers=num_workers)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> train_iter, test_iter</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># batchsize可以根据电脑的实际情况进行修改</span></span><br><span class="line">batchsize = <span class="number">128</span></span><br><span class="line"><span class="comment"># 由于imagenet数据集图片的形状为224*224，所以需要将输入的图片resize为224*224</span></span><br><span class="line">train_iter, test_iter = load_data(batch_size=batchsize, resize=<span class="number">224</span>)</span><br></pre></td></tr></table></figure><h4 id="2-4-训练"><a href="#2-4-训练" class="headerlink" title="2.4 训练"></a>2.4 训练</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># lr, num_epochos可以根据实际情况进行修改</span></span><br><span class="line">lr, num_epochos = <span class="number">0.001</span>, <span class="number">5</span></span><br><span class="line"><span class="comment"># 优化算法采用Adam算法，也可以选择torch.optim包下其他的优化算法</span></span><br><span class="line">optimizer = torch.optim.Adam(alexnet.parameters(), lr=lr)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">train</span><span class="params">(train_iter, test_iter, net, optimizer, device, num_epochs)</span>:</span></span><br><span class="line">    <span class="comment"># 将网络部署在gpu设备上</span></span><br><span class="line">    net = net.to(device)</span><br><span class="line">    print(<span class="string">"training on"</span>, device)</span><br><span class="line">    <span class="comment"># 交叉熵</span></span><br><span class="line">    loss = torch.nn.CrossEntropyLoss()</span><br><span class="line">    batch_count = <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> epoch <span class="keyword">in</span> range(num_epochs):</span><br><span class="line">        train_l_sum, train_acc_sum, n, start = <span class="number">0.0</span>, <span class="number">0.0</span>, <span class="number">0</span>, time.time()</span><br><span class="line">        <span class="keyword">for</span> X, y <span class="keyword">in</span> train_iter:</span><br><span class="line">             <span class="comment"># 输入的属性</span></span><br><span class="line">            X = X.to(device)</span><br><span class="line">            <span class="comment"># 标签</span></span><br><span class="line">            y = y.to(device)</span><br><span class="line">            <span class="comment"># 预测</span></span><br><span class="line">            y_hat = net(X)</span><br><span class="line">            <span class="comment"># 计算损失</span></span><br><span class="line">            l = loss(y_hat, y)</span><br><span class="line">            <span class="comment"># 梯度下降</span></span><br><span class="line">            optimizer.zero_grad()</span><br><span class="line">            l.backward()</span><br><span class="line">            optimizer.step()</span><br><span class="line">            </span><br><span class="line">            train_l_sum += l.cpu().item()</span><br><span class="line">            train_acc_sum += (y_hat.argmax(dim=<span class="number">1</span>) == y).sum().cpu().item()</span><br><span class="line">            n += y.shape[<span class="number">0</span>]</span><br><span class="line">            batch_count += <span class="number">1</span></span><br><span class="line">        <span class="comment"># 测试集的准确率</span></span><br><span class="line">        test_acc = evaluate_accuracy(test_iter, net)</span><br><span class="line">        print(<span class="string">'epoch &#123;&#125;, loss &#123;:.4f&#125;, train acc &#123;:.4f&#125;, test acc&#123;:.4f&#125;, time &#123;:.2f&#125; sec'</span></span><br><span class="line">              .format(epoch + <span class="number">1</span>, train_l_sum / batch_count, train_acc_sum / n, test_acc, time.time() - start))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 评估模型在测试集的表现</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">evaluate_accuracy</span><span class="params">(data_iter, net, device=None)</span>:</span></span><br><span class="line">    <span class="keyword">if</span> device <span class="keyword">is</span> <span class="literal">None</span> <span class="keyword">and</span> isinstance(net, torch.nn.Module):</span><br><span class="line">        <span class="comment"># 如果没指定device就使用net的device</span></span><br><span class="line">        device = list(net.parameters())[<span class="number">0</span>].device</span><br><span class="line">    acc_sum, n = <span class="number">0.0</span>, <span class="number">0</span></span><br><span class="line">    <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">        <span class="keyword">for</span> X, y <span class="keyword">in</span> data_iter:</span><br><span class="line">            <span class="keyword">if</span> isinstance(net, torch.nn.Module):</span><br><span class="line">                <span class="comment"># 评估模式, 关闭dropout</span></span><br><span class="line">                net.eval()  </span><br><span class="line">                acc_sum += (net(X.to(device)).argmax(dim=<span class="number">1</span>) == y.to(device)).float().sum().cpu().item()</span><br><span class="line">                <span class="comment"># 改回训练模式</span></span><br><span class="line">                net.train() </span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                <span class="keyword">if</span> (<span class="string">'is_training'</span> <span class="keyword">in</span> net.__code__.co_varnames):  <span class="comment"># 如果有is_training这个参数</span></span><br><span class="line">                    <span class="comment"># 将is_training设置成False</span></span><br><span class="line">                    acc_sum += (net(X, is_training=<span class="literal">False</span>).argmax(dim=<span class="number">1</span>) == y).float().sum().item()</span><br><span class="line">                <span class="keyword">else</span>:</span><br><span class="line">                    acc_sum += (net(X).argmax(dim=<span class="number">1</span>) == y).float().sum().item()</span><br><span class="line">            n += y.shape[<span class="number">0</span>]</span><br><span class="line">    <span class="keyword">return</span> acc_sum / n</span><br><span class="line"></span><br><span class="line">train(train_iter=train_iter, test_iter=test_iter, net=alexnet, optimizer=optimizer, </span><br><span class="line">      device=device,num_epochs=num_epochos)</span><br></pre></td></tr></table></figure><h3 id="3-图像增广"><a href="#3-图像增广" class="headerlink" title="3. 图像增广"></a>3. 图像增广</h3><h4 id="3-1-导入需要的包"><a href="#3-1-导入需要的包" class="headerlink" title="3.1 导入需要的包"></a>3.1 导入需要的包</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">%matplotlib inline</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> nn, optim</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> Dataset, DataLoader</span><br><span class="line"><span class="keyword">import</span> torchvision</span><br><span class="line"><span class="keyword">from</span> IPython <span class="keyword">import</span> display</span><br><span class="line"><span class="keyword">from</span> matplotlib <span class="keyword">import</span> pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image</span><br><span class="line">os.environ[<span class="string">"CUDA_VISIBLE_DEVICES"</span>] = <span class="string">"0"</span></span><br><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"></span><br><span class="line">device = torch.device(<span class="string">'cuda'</span> <span class="keyword">if</span> torch.cuda.is_available() <span class="keyword">else</span> <span class="string">'cpu'</span>)</span><br><span class="line">device</span><br></pre></td></tr></table></figure><h4 id="3-2-读取图片进行测试"><a href="#3-2-读取图片进行测试" class="headerlink" title="3.2 读取图片进行测试"></a>3.2 读取图片进行测试</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 读取图片</span></span><br><span class="line">display.set_matplotlib_formats(<span class="string">'svg'</span>)</span><br><span class="line">plt.rcParams[<span class="string">'figure.figsize'</span>] = (<span class="number">3.5</span>, <span class="number">2.5</span>)</span><br><span class="line">img = Image.open(<span class="string">'./dog.jpg'</span>)</span><br><span class="line">plt.imshow(img)</span><br></pre></td></tr></table></figure><h4 id="3-3-常用的图像增广的方法"><a href="#3-3-常用的图像增广的方法" class="headerlink" title="3.3 常用的图像增广的方法"></a>3.3 常用的图像增广的方法</h4><h5 id="3-3-1-定义展示函数"><a href="#3-3-1-定义展示函数" class="headerlink" title="3.3.1 定义展示函数"></a>3.3.1 定义展示函数</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">show_images</span><span class="params">(imgs, num_rows, num_cols, scale=<span class="number">2</span>)</span>:</span></span><br><span class="line">    figsize = (num_cols * scale, num_rows * scale)</span><br><span class="line">    _, axes = d2l.plt.subplots(num_rows, num_cols, figsize=figsize)</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(num_rows):</span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> range(num_cols):</span><br><span class="line">            axes[i][j].imshow(imgs[i * num_cols + j])</span><br><span class="line">            axes[i][j].axes.get_xaxis().set_visible(<span class="literal">False</span>)</span><br><span class="line">            axes[i][j].axes.get_yaxis().set_visible(<span class="literal">False</span>)</span><br><span class="line">    <span class="keyword">return</span> axes</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">apply</span><span class="params">(img, aug, num_rows=<span class="number">2</span>, num_cols=<span class="number">4</span>, scale=<span class="number">1.5</span>)</span>:</span></span><br><span class="line">    Y = [aug(img) <span class="keyword">for</span> _ <span class="keyword">in</span> range(num_rows * num_cols)]</span><br><span class="line">    show_images(Y, num_rows, num_cols, scale)</span><br></pre></td></tr></table></figure><h5 id="3-3-2-图像的翻转和裁剪"><a href="#3-3-2-图像的翻转和裁剪" class="headerlink" title="3.3.2 图像的翻转和裁剪"></a>3.3.2 图像的翻转和裁剪</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 一半概率的图像左右翻转</span></span><br><span class="line">apply(img, torchvision.transforms.RandomHorizontalFlip())</span><br><span class="line"><span class="comment"># 一半概率的图像上下翻转</span></span><br><span class="line">apply(img, torchvision.transforms.RandomVerticalFlip())</span><br><span class="line"><span class="comment"># 随机选取图像中10%-50%的区域，区域的宽和高之比为0.5-2，将该区域缩放到200像素</span></span><br><span class="line">shape_aug = torchvision.transforms.RandomResizedCrop(<span class="number">200</span>, scale=(<span class="number">0.1</span>, <span class="number">0.5</span>), ratio=(<span class="number">0.5</span>, <span class="number">2</span>))</span><br><span class="line">apply(img, shape_aug)</span><br></pre></td></tr></table></figure><h5 id="3-3-3-颜色变化"><a href="#3-3-3-颜色变化" class="headerlink" title="3.3.3 颜色变化"></a>3.3.3 颜色变化</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 将图像的亮度随机变化为源图像的50%</span></span><br><span class="line">apply(img, torchvision.transforms.ColorJitter(brightness=<span class="number">0.5</span>))</span><br><span class="line"><span class="comment"># 将图像的色调随机变化为源图像的50%</span></span><br><span class="line">apply(img, torchvision.transforms.ColorJitter(hue=<span class="number">0.5</span>))</span><br><span class="line"><span class="comment"># 将图像的对比度随机变化为源图像的50%</span></span><br><span class="line">apply(img, torchvision.transforms.ColorJitter(contrast=<span class="number">0.5</span>))</span><br><span class="line"><span class="comment"># 同时设置修改亮度，色调，对比度</span></span><br><span class="line"><span class="comment"># 将图像的亮度随机变化为源图像的50%</span></span><br><span class="line">apply(img, torchvision.transforms.ColorJitter(</span><br><span class="line">   brightness=<span class="number">0.5</span>, hue=<span class="number">0.5</span>, contrast=<span class="number">0.5</span>))</span><br></pre></td></tr></table></figure><h5 id="3-3-4-叠加多种图像增广的方法"><a href="#3-3-4-叠加多种图像增广的方法" class="headerlink" title="3.3.4 叠加多种图像增广的方法"></a>3.3.4 叠加多种图像增广的方法</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">augs = torchvision.transforms.Compose([</span><br><span class="line">    torchvision.transforms.RandomHorizontalFlip(), </span><br><span class="line">    torchvision.transforms.ColorJitter(</span><br><span class="line">        brightness=<span class="number">0.5</span>, hue=<span class="number">0.5</span>, contrast=<span class="number">0.5</span>),</span><br><span class="line">    torchvision.transforms.RandomResizedCrop(<span class="number">200</span>, scale=(<span class="number">0.1</span>, <span class="number">0.5</span>), ratio=(<span class="number">0.5</span>, <span class="number">2</span>))</span><br><span class="line">])</span><br><span class="line">apply(img, augs)</span><br></pre></td></tr></table></figure><h5 id="3-3-5-训练"><a href="#3-3-5-训练" class="headerlink" title="3.3.5 训练"></a>3.3.5 训练</h5><p>在读取数据函数load_data里面添加图像增广的方法</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">load_data</span><span class="params">(batch_size, resize=None, root=<span class="string">'./data/CIFAR10'</span>)</span>:</span></span><br><span class="line">    trans = []</span><br><span class="line">    <span class="keyword">if</span> resize:</span><br><span class="line">        trans.append(torchvision.transforms.Resize(size=resize))</span><br><span class="line"><span class="comment"># 根据实际情况添加图像增广的方法</span></span><br><span class="line">    trans.append(torchvision.transforms.RandomHorizontalFlip())</span><br><span class="line">    trans.append(torchvision.transforms.ToTensor())</span><br><span class="line">    </span><br><span class="line">    transform = torchvision.transforms.Compose(trans)</span><br><span class="line"></span><br><span class="line">    data_train = torchvision.datasets.CIFAR10(root=root, train=<span class="literal">True</span>, download=<span class="literal">True</span>, transform=transform)</span><br><span class="line">    data_test = torchvision.datasets.CIFAR10(root=root, train=<span class="literal">False</span>, download=<span class="literal">True</span>, transform=transform)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">if</span> sys.platform.startswith(<span class="string">'win'</span>):</span><br><span class="line">        num_workers = <span class="number">0</span>  <span class="comment"># 0表示不用额外的进程来加速读取数据</span></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        num_workers = <span class="number">4</span></span><br><span class="line">    </span><br><span class="line">    train_iter = torch.utils.data.DataLoader(data_train, batch_size=batch_size, shuffle=<span class="literal">True</span>, num_workers=num_workers)</span><br><span class="line">    test_iter = torch.utils.data.DataLoader(data_test, batch_size=batch_size, shuffle=<span class="literal">False</span>, num_workers=num_workers)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> train_iter, test_iter</span><br></pre></td></tr></table></figure><h3 id="4-模型的微调"><a href="#4-模型的微调" class="headerlink" title="4. 模型的微调"></a>4. 模型的微调</h3><h4 id="4-1-简介"><a href="#4-1-简介" class="headerlink" title="4.1 简介"></a>4.1 简介</h4><p>pytorch继承好了许多预训练的模型，这些的模型的参数已经十分优秀了，所以在根据自己的数据集进行训练时可以借鉴预训练好模型的参数。</p><h4 id="4-2-加载数据集"><a href="#4-2-加载数据集" class="headerlink" title="4.2 加载数据集"></a>4.2 加载数据集</h4><p>使用热狗数据集进行测试<a href="https://apache-mxnet.s3-accelerate.amazonaws.com/gluon/dataset/hotdog.zip" target="_blank" rel="noopener">点击下载</a></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line">data_dir = <span class="string">'./data'</span></span><br><span class="line">os.listdir(os.path.join(data_dir, <span class="string">'hotdog'</span>))</span><br></pre></td></tr></table></figure><h4 id="4-3-定义和初始化模型"><a href="#4-3-定义和初始化模型" class="headerlink" title="4.3 定义和初始化模型"></a>4.3 定义和初始化模型</h4><h5 id="4-3-1-查看原模型最后一层的结构"><a href="#4-3-1-查看原模型最后一层的结构" class="headerlink" title="4.3.1 查看原模型最后一层的结构"></a>4.3.1 查看原模型最后一层的结构</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">alexnet.classifier</span><br></pre></td></tr></table></figure><h5 id="4-3-2-修改原模型最后一层的结构，输出改为2"><a href="#4-3-2-修改原模型最后一层的结构，输出改为2" class="headerlink" title="4.3.2 修改原模型最后一层的结构，输出改为2"></a>4.3.2 修改原模型最后一层的结构，输出改为2</h5><p>选择其他预训练的模型基本操作都是相同的，把最后一层的输出改成实际需要的输出</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">alexnet.classifier = nn.Sequential(</span><br><span class="line">            <span class="comment"># 第一层全连接层</span></span><br><span class="line">            nn.Linear(<span class="number">9216</span>, <span class="number">4096</span>),</span><br><span class="line">            nn.ReLU(),</span><br><span class="line">            nn.Dropout(<span class="number">0.5</span>),</span><br><span class="line">            </span><br><span class="line">            <span class="comment"># 第二层全连接层</span></span><br><span class="line">            nn.Linear(<span class="number">4096</span>, <span class="number">4096</span>),</span><br><span class="line">            nn.ReLU(),</span><br><span class="line">            nn.Dropout(<span class="number">0.5</span>),</span><br><span class="line">            </span><br><span class="line">            <span class="comment"># 第三层全连接层（输出层）</span></span><br><span class="line">            nn.Linear(<span class="number">4096</span>, <span class="number">10</span>)</span><br><span class="line">        )</span><br><span class="line">alexnet.classifier</span><br></pre></td></tr></table></figure><h5 id="4-3-3-获取模型参数"><a href="#4-3-3-获取模型参数" class="headerlink" title="4.3.3 获取模型参数"></a>4.3.3 获取模型参数</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">output_params = list(map(id, alexnet.classifier.parameters()))</span><br><span class="line">features_params = filter(<span class="keyword">lambda</span> p: id(p) <span class="keyword">not</span> <span class="keyword">in</span> output_params, alexnet.parameters())</span><br><span class="line"></span><br><span class="line">lr = <span class="number">0.01</span></span><br><span class="line">optimizer = optim.Adam([</span><br><span class="line">    &#123;<span class="string">'params'</span>: features_params&#125;,</span><br><span class="line">    &#123;<span class="string">'params'</span>: alexnet.classifier.parameters(), <span class="string">'lr'</span>: lr * <span class="number">100</span>&#125;</span><br><span class="line">], lr=lr, weight_decay=<span class="number">0.001</span>)</span><br></pre></td></tr></table></figure><h5 id="4-3-4-设置图像增广的方法"><a href="#4-3-4-设置图像增广的方法" class="headerlink" title="4.3.4 设置图像增广的方法"></a>4.3.4 设置图像增广的方法</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> torchvision <span class="keyword">import</span> transforms</span><br><span class="line">normalize = transforms.Normalize(mean=[<span class="number">0.485</span>, <span class="number">0.456</span>, <span class="number">0.406</span>], std=[<span class="number">0.229</span>, <span class="number">0.224</span>, <span class="number">0.225</span>])</span><br><span class="line">train_augs = transforms.Compose([</span><br><span class="line">    transforms.RandomResizedCrop(size=<span class="number">224</span>),</span><br><span class="line">    transforms.RandomHorizontalFlip(),</span><br><span class="line">    transforms.ToTensor(),</span><br><span class="line">    normalize</span><br><span class="line">])</span><br><span class="line">test_augs = transforms.Compose([</span><br><span class="line">    transforms.Resize(size=<span class="number">256</span>),</span><br><span class="line">    transforms.CenterCrop(size=<span class="number">224</span>),</span><br><span class="line">    transforms.ToTensor(),</span><br><span class="line">    normalize</span><br><span class="line">])</span><br></pre></td></tr></table></figure><h5 id="4-3-5-训练"><a href="#4-3-5-训练" class="headerlink" title="4.3.5 训练"></a>4.3.5 训练</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> Dataset, DataLoader</span><br><span class="line"><span class="keyword">from</span> torchvision.datasets <span class="keyword">import</span> ImageFolder</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">train_fine_tuning</span><span class="params">(net, optimizer, batch_size=<span class="number">5</span>, num_epochs=<span class="number">5</span>)</span>:</span></span><br><span class="line">    train_iter = DataLoader(ImageFolder(os.path.join(data_dir, <span class="string">'hotdog/train'</span>), transform=train_augs),</span><br><span class="line">                            batch_size, shuffle=<span class="literal">True</span>)</span><br><span class="line">    test_iter = DataLoader(ImageFolder(os.path.join(data_dir, <span class="string">'hotdog/test'</span>), transform=test_augs),</span><br><span class="line">                           batch_size)</span><br><span class="line">    train(train_iter, test_iter, net, optimizer, device, num_epochs)</span><br><span class="line"></span><br><span class="line">train_fine_tuning(alexnet, optimizer)</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h3 id=&quot;1-AlexNet的网络结构&quot;&gt;&lt;a href=&quot;#1-AlexNet的网络结构&quot; class=&quot;headerlink&quot; title=&quot;1. AlexNet的网络结构&quot;&gt;&lt;/a&gt;1. AlexNet的网络结构&lt;/h3&gt;&lt;p&gt;&lt;img src=&quot;http://blo
      
    
    </summary>
    
    
      <category term="pytorch" scheme="http://yoursite.com/categories/pytorch/"/>
    
    
      <category term="pytorch" scheme="http://yoursite.com/tags/pytorch/"/>
    
      <category term="AlexNet" scheme="http://yoursite.com/tags/AlexNet/"/>
    
  </entry>
  
  <entry>
    <title>pytorch-线性回归</title>
    <link href="http://yoursite.com/2020/04/15/pytorch-%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/"/>
    <id>http://yoursite.com/2020/04/15/pytorch-%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/</id>
    <published>2020-04-14T16:00:00.000Z</published>
    <updated>2020-04-20T02:31:55.652Z</updated>
    
    <content type="html"><![CDATA[<h3 id="1-导入相应的包"><a href="#1-导入相应的包" class="headerlink" title="1. 导入相应的包"></a>1. 导入相应的包</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br></pre></td></tr></table></figure><h3 id="2-创建模型y-wx-b"><a href="#2-创建模型y-wx-b" class="headerlink" title="2. 创建模型y=wx+b"></a>2. 创建模型<code>y=wx+b</code></h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">LinearModel</span><span class="params">(nn.Module)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, ndim)</span>:</span></span><br><span class="line">        super(LinearModel, self).__init__()</span><br><span class="line">        self.ndim = ndim</span><br><span class="line">        </span><br><span class="line">        self.weight = nn.Parameter(torch.randn(ndim, <span class="number">2</span>))</span><br><span class="line">        self.bias = nn.Parameter(torch.randn(<span class="number">1</span>))</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, x)</span>:</span></span><br><span class="line">        <span class="comment"># y = wx + b</span></span><br><span class="line">        <span class="keyword">return</span> x.mm(self.weight) + self.bias</span><br></pre></td></tr></table></figure><h3 id="3-创建x输入并输出y"><a href="#3-创建x输入并输出y" class="headerlink" title="3. 创建x输入并输出y"></a>3. 创建<code>x</code>输入并输出<code>y</code></h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">lm = LinearModel(<span class="number">5</span>)</span><br><span class="line">x = torch.randn(<span class="number">4</span>, <span class="number">5</span>)</span><br><span class="line">lm(x)</span><br></pre></td></tr></table></figure><h3 id="4-获取模型参数的生成器"><a href="#4-获取模型参数的生成器" class="headerlink" title="4.  获取模型参数的生成器"></a>4.  获取模型参数的生成器</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">lm.named_parameters()</span><br></pre></td></tr></table></figure><h3 id="5-将生成器转换为列表"><a href="#5-将生成器转换为列表" class="headerlink" title="5. 将生成器转换为列表"></a>5. 将生成器转换为列表</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">list(lm.named_parameters())</span><br></pre></td></tr></table></figure><h3 id="6-将模型参数转移到gpu上"><a href="#6-将模型参数转移到gpu上" class="headerlink" title="6. 将模型参数转移到gpu上"></a>6. 将模型参数转移到gpu上</h3>  <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">lm.cuda()</span><br><span class="line">list(lm.parameters())</span><br></pre></td></tr></table></figure><h3 id="7-转换模型参数为半精度浮点数"><a href="#7-转换模型参数为半精度浮点数" class="headerlink" title="7. 转换模型参数为半精度浮点数"></a>7. 转换模型参数为半精度浮点数</h3> <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">lm.half()</span><br><span class="line">list(lm.named_parameters())</span><br></pre></td></tr></table></figure><h3 id="8-实战-预测波士顿房价"><a href="#8-实战-预测波士顿房价" class="headerlink" title="8.实战-预测波士顿房价"></a>8.实战-预测波士顿房价</h3><table><thead><tr><th>No</th><th>属性</th><th>数据类型</th><th>字段描述</th></tr></thead><tbody><tr><td>1</td><td>CRIM</td><td>Float</td><td>城镇人均犯罪率</td></tr><tr><td>2</td><td>ZN</td><td>Float</td><td>占地面积超过2.5万平方英尺的住宅用地比例</td></tr><tr><td>3</td><td>INDUS</td><td>Float</td><td>城镇非零售业务地区的比例</td></tr><tr><td>4</td><td>CHAS</td><td>Integer</td><td>查尔斯河虚拟变量 (= 1 如果土地在河边；否则是0)</td></tr><tr><td>5</td><td>NOX</td><td>Float</td><td>一氧化氮浓度（每1000万份）</td></tr><tr><td>6</td><td>RM</td><td>Float</td><td>平均每居民房数</td></tr><tr><td>7</td><td>AGE</td><td>Float</td><td>在1940年之前建成的所有者占用单位的比例</td></tr><tr><td>8</td><td>DIS</td><td>Float</td><td>与五个波士顿就业中心的加权距离</td></tr><tr><td>9</td><td>RAD</td><td>Integer</td><td>辐射状公路的可达性指数</td></tr><tr><td>10</td><td>TAX</td><td>Float</td><td>每10,000美元的全额物业税率</td></tr><tr><td>11</td><td>PTRATIO</td><td>Float</td><td>城镇师生比例</td></tr><tr><td>12</td><td>B</td><td>Float</td><td>1000（Bk - 0.63）^ 2其中Bk是城镇黑人的比例</td></tr><tr><td>13</td><td>LSTAT</td><td>Float</td><td>人口中地位较低人群的百分数</td></tr><tr><td>14</td><td>MEDV</td><td>Float</td><td>（目标变量/类别属性）以1000美元计算的自有住房的中位数</td></tr></tbody></table><p>波士顿房价数据集共有506条数据，13个特征</p><h4 id="8-1-通过sklearn导入数据集"><a href="#8-1-通过sklearn导入数据集" class="headerlink" title="8.1 通过sklearn导入数据集"></a>8.1 通过<code>sklearn</code>导入数据集</h4> <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn .datasets <span class="keyword">import</span> load_boston</span><br></pre></td></tr></table></figure><h4 id="8-2-读取数据，定义优化器、损失函数"><a href="#8-2-读取数据，定义优化器、损失函数" class="headerlink" title="8.2 读取数据，定义优化器、损失函数"></a>8.2 读取数据，定义优化器、损失函数</h4> <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"> boston = load_boston()</span><br><span class="line">lm = LinearModel(<span class="number">13</span>)</span><br><span class="line"><span class="comment"># 定义平方损失函数</span></span><br><span class="line">criterion = nn.MSELoss()</span><br><span class="line"><span class="comment"># 定义优化器</span></span><br><span class="line">optim = torch.optim.SGD(lm.parameters(), lr=<span class="number">1e-6</span>)</span><br><span class="line"><span class="comment"># 将数据转换为tensor类型的数据</span></span><br><span class="line">data = torch.tensor(boston[<span class="string">"data"</span>], requires_grad=<span class="literal">True</span>, dtype=torch.float32)</span><br><span class="line">target = torch.tensor(boston[<span class="string">"target"</span>], dtype=torch.float32)</span><br></pre></td></tr></table></figure><h4 id="8-3-训练模型"><a href="#8-3-训练模型" class="headerlink" title="8.3 训练模型"></a>8.3 训练模型</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> step <span class="keyword">in</span> range(<span class="number">10000</span>):</span><br><span class="line">    <span class="comment"># 计算模型预测的结果</span></span><br><span class="line">    predict = lm(data)</span><br><span class="line">    <span class="comment"># 计算损失函数</span></span><br><span class="line">    loss = criterion(predict, target)</span><br><span class="line">    <span class="comment"># 每100步输出一次信息</span></span><br><span class="line">    <span class="keyword">if</span> step <span class="keyword">and</span> step % <span class="number">1000</span> == <span class="number">0</span>:</span><br><span class="line">        print(<span class="string">"Loss: &#123;:.4f&#125;"</span>.format(loss.item()))</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 梯度清零</span></span><br><span class="line">    optim.zero_grad()</span><br><span class="line">    <span class="comment"># 反向传播</span></span><br><span class="line">    loss.backward()</span><br><span class="line">    optim.step()</span><br></pre></td></tr></table></figure><h3 id="9-使用tensorboard查看训练结果"><a href="#9-使用tensorboard查看训练结果" class="headerlink" title="9.使用tensorboard查看训练结果"></a>9.使用<code>tensorboard</code>查看训练结果</h3><h4 id="9-1-下载tensorboard"><a href="#9-1-下载tensorboard" class="headerlink" title="9.1 下载tensorboard"></a>9.1 下载<code>tensorboard</code></h4><blockquote><p>conda install tensorboard</p><p>pip install future</p></blockquote><h4 id="9-2-修改训练代码"><a href="#9-2-修改训练代码" class="headerlink" title="9.2 修改训练代码"></a>9.2 修改训练代码</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> torch.utils.tensorboard <span class="keyword">import</span> SummaryWriter</span><br><span class="line"></span><br><span class="line"><span class="comment"># tesorboard输出类</span></span><br><span class="line">writer = SummaryWriter()</span><br><span class="line"><span class="comment"># 训练</span></span><br><span class="line"><span class="keyword">for</span> step <span class="keyword">in</span> range(<span class="number">10000</span>):</span><br><span class="line">    <span class="comment"># 计算模型预测的结果</span></span><br><span class="line">    predict = lm(data)</span><br><span class="line">    <span class="comment"># 计算损失函数</span></span><br><span class="line">    loss = criterion(predict, target)</span><br><span class="line">    </span><br><span class="line">    writer.add_scalar(<span class="string">"loss/train"</span>, loss, step)</span><br><span class="line">    <span class="comment"># 输出权重图</span></span><br><span class="line">    writer.add_histogram(<span class="string">"loss/weight"</span>, lm.weight, step)</span><br><span class="line">    writer.add_histogram(<span class="string">"loss/bias"</span>, lm.bias, step)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 每100步输出一次信息</span></span><br><span class="line">    <span class="keyword">if</span> step <span class="keyword">and</span> step % <span class="number">1000</span> == <span class="number">0</span>:</span><br><span class="line">        print(<span class="string">"Loss: &#123;:.4f&#125;"</span>.format(loss.item()))</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 梯度清零</span></span><br><span class="line">    optim.zero_grad()</span><br><span class="line">    <span class="comment"># 反向传播</span></span><br><span class="line">    loss.backward()</span><br><span class="line">    optim.step()</span><br><span class="line">```</span><br><span class="line"></span><br><span class="line"><span class="comment">#### 9.3 打开`tensorboard`</span></span><br><span class="line"></span><br><span class="line">```linux</span><br><span class="line"><span class="comment"># 打开cmd，运行</span></span><br><span class="line">tensorboard --logdir run文件夹地址 --host=<span class="number">127.0</span><span class="number">.0</span><span class="number">.1</span></span><br><span class="line"><span class="comment"># 访问127.0.0.1:6006</span></span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h3 id=&quot;1-导入相应的包&quot;&gt;&lt;a href=&quot;#1-导入相应的包&quot; class=&quot;headerlink&quot; title=&quot;1. 导入相应的包&quot;&gt;&lt;/a&gt;1. 导入相应的包&lt;/h3&gt;&lt;figure class=&quot;highlight python&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td
      
    
    </summary>
    
    
      <category term="pytorch" scheme="http://yoursite.com/categories/pytorch/"/>
    
    
      <category term="pytorch" scheme="http://yoursite.com/tags/pytorch/"/>
    
  </entry>
  
  <entry>
    <title>WebSocket-实现用户登录和在线聊天室（python）</title>
    <link href="http://yoursite.com/2020/04/13/WebSocket-%E5%AE%9E%E7%8E%B0%E7%94%A8%E6%88%B7%E7%99%BB%E5%BD%95%E5%92%8C%E5%9C%A8%E7%BA%BF%E8%81%8A%E5%A4%A9%E5%AE%A4%EF%BC%88python%EF%BC%89/"/>
    <id>http://yoursite.com/2020/04/13/WebSocket-%E5%AE%9E%E7%8E%B0%E7%94%A8%E6%88%B7%E7%99%BB%E5%BD%95%E5%92%8C%E5%9C%A8%E7%BA%BF%E8%81%8A%E5%A4%A9%E5%AE%A4%EF%BC%88python%EF%BC%89/</id>
    <published>2020-04-13T14:02:26.000Z</published>
    <updated>2020-04-13T14:03:40.229Z</updated>
    
    <content type="html"><![CDATA[<h5 id="1-安装tornado包"><a href="#1-安装tornado包" class="headerlink" title="1. 安装tornado包"></a>1. 安装<code>tornado</code>包</h5><blockquote><p>pip install tornado</p></blockquote><h5 id="2-文件目录结构"><a href="#2-文件目录结构" class="headerlink" title="2. 文件目录结构"></a>2. 文件目录结构</h5><blockquote><p>WebChat</p><blockquote><p>static</p><blockquote><p>chat.js<br>jquery.min.js</p></blockquote><p>templates</p><blockquote><p>index.html<br>login.html<br>message.html</p></blockquote><p>chatdemo.py</p></blockquote></blockquote><h5 id="3-服务端代码"><a href="#3-服务端代码" class="headerlink" title="3. 服务端代码"></a>3. 服务端代码</h5><p>chatdemo.py</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding: UTF-8 -*-</span></span><br><span class="line"><span class="keyword">import</span> logging</span><br><span class="line"><span class="keyword">import</span> tornado.escape</span><br><span class="line"><span class="keyword">import</span> tornado.ioloop</span><br><span class="line"><span class="keyword">import</span> tornado.options</span><br><span class="line"><span class="keyword">import</span> tornado.web</span><br><span class="line"><span class="keyword">import</span> tornado.websocket</span><br><span class="line"><span class="keyword">import</span> os.path</span><br><span class="line"><span class="keyword">import</span> uuid</span><br><span class="line"><span class="keyword">import</span> datetime</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> tornado.options <span class="keyword">import</span> define, options</span><br><span class="line"></span><br><span class="line"><span class="comment"># 设置端口</span></span><br><span class="line">define(<span class="string">"port"</span>, default=<span class="number">1113</span>, help=<span class="string">"运行端口：1113"</span>, type=int)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Application</span><span class="params">(tornado.web.Application)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="comment"># 路由映射</span></span><br><span class="line">        handlers = [</span><br><span class="line">            (<span class="string">r"/"</span>, IndexHandler),</span><br><span class="line">            (<span class="string">r"/login"</span>, MainHandler),</span><br><span class="line">            (<span class="string">r"/chatsocket"</span>, ChatSocketHandler),</span><br><span class="line">        ]</span><br><span class="line">        <span class="comment"># 配置静态资源信息</span></span><br><span class="line">        settings = dict(</span><br><span class="line">            <span class="comment"># cookie 安全认证</span></span><br><span class="line">            cookie_secret=<span class="string">"__TODO:_GENERATE_YOUR_OWN_RANDOM_VALUE_HERE__"</span>,</span><br><span class="line">            xsrf_cookies=<span class="literal">True</span>,</span><br><span class="line">            template_path=os.path.join(os.path.dirname(__file__), <span class="string">"templates"</span>),</span><br><span class="line">            static_path=os.path.join(os.path.dirname(__file__), <span class="string">"static"</span>),</span><br><span class="line">        )</span><br><span class="line">        super(Application, self).__init__(handlers, **settings)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># “/”映射， 访问127.0.0.1:8080返回主页面</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">IndexHandler</span><span class="params">(tornado.web.RequestHandler)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">get</span><span class="params">(self)</span>:</span></span><br><span class="line">        self.render(<span class="string">"login.html"</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MainHandler</span><span class="params">(tornado.web.RequestHandler)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">get</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="comment"># 获取用户名</span></span><br><span class="line">        username = self.get_argument(<span class="string">"userName"</span>)</span><br><span class="line">        <span class="comment"># 获取密码</span></span><br><span class="line">        userpwd = self.get_argument(<span class="string">"userPwd"</span>)</span><br><span class="line">        print(username + <span class="string">" "</span> + userpwd)</span><br><span class="line"></span><br><span class="line">        ChatSocketHandler.client_id = username</span><br><span class="line">        self.render(<span class="string">"index.html"</span>, messages=ChatSocketHandler.cache, clients=ChatSocketHandler.waiters,</span><br><span class="line">                    username=<span class="string">"&#123;&#125;"</span>.format(ChatSocketHandler.client_id))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">ChatSocketHandler</span><span class="params">(tornado.websocket.WebSocketHandler)</span>:</span></span><br><span class="line">    <span class="comment"># 保持所有在线websocket链接，waiters保存着每个连接到服务器的浏览器信息</span></span><br><span class="line">    waiters = set()</span><br><span class="line">    cache = []</span><br><span class="line">    cache_size = <span class="number">200</span></span><br><span class="line">    client_id = <span class="string">""</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">get_compression_options</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="keyword">return</span> &#123;&#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment"># websocket建立连接时调用</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">open</span><span class="params">(self)</span>:</span></span><br><span class="line">        self.username = <span class="string">"用户: &#123;&#125;"</span>.format(self.client_id)</span><br><span class="line">        <span class="comment"># 建立连接后将浏览器实例加入到waiters</span></span><br><span class="line">        ChatSocketHandler.waiters.add(self)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 建立连接后返回给客户端的值</span></span><br><span class="line">        chat = &#123;</span><br><span class="line">            <span class="string">"id"</span>: str(uuid.uuid4()),</span><br><span class="line">            <span class="string">"type"</span>: <span class="string">"online"</span>,</span><br><span class="line">            <span class="string">"client_id"</span>: self.client_id,</span><br><span class="line">            <span class="string">"username"</span>: self.username,</span><br><span class="line">            <span class="string">"datetime"</span>: datetime.datetime.now().strftime(<span class="string">"%Y-%m-%d %H:%M:%S"</span>)</span><br><span class="line">        &#125;</span><br><span class="line">        ChatSocketHandler.send_updates(chat)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># websocket断开连接时调用</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">on_close</span><span class="params">(self)</span>:</span></span><br><span class="line">        ChatSocketHandler.waiters.remove(self)</span><br><span class="line">        chat = &#123;</span><br><span class="line">            <span class="string">"id"</span>: str(uuid.uuid4()),</span><br><span class="line">            <span class="string">"type"</span>: <span class="string">"offline"</span>,</span><br><span class="line">            <span class="string">"client_id"</span>: self.client_id,</span><br><span class="line">            <span class="string">"username"</span>: self.username,</span><br><span class="line">            <span class="string">"datetime"</span>: datetime.datetime.now().strftime(<span class="string">"%Y-%m-%d %H:%M:%S"</span>)</span><br><span class="line">        &#125;</span><br><span class="line">        ChatSocketHandler.send_updates(chat)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 更新缓存，超出存储限制后删除之前的消息</span></span><br><span class="line"><span class="meta">    @classmethod</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">update_cache</span><span class="params">(cls, chat)</span>:</span></span><br><span class="line">        cls.cache.append(chat)</span><br><span class="line">        <span class="keyword">if</span> len(cls.cache) &gt; cls.cache_size:</span><br><span class="line">            cls.cache = cls.cache[-cls.cache_size:]</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 向所有客户端发送消息</span></span><br><span class="line"><span class="meta">    @classmethod</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">send_updates</span><span class="params">(cls, chat)</span>:</span></span><br><span class="line">        logging.info(<span class="string">"给 &#123;&#125; 位游客发送消息"</span>.format(len(cls.waiters)))</span><br><span class="line">        <span class="comment"># 遍历所有已建立的浏览器实例信息，发送消息</span></span><br><span class="line">        <span class="keyword">for</span> waiter <span class="keyword">in</span> cls.waiters:</span><br><span class="line">            <span class="keyword">try</span>:</span><br><span class="line">                waiter.write_message(chat)</span><br><span class="line">            <span class="keyword">except</span>:</span><br><span class="line">                logging.error(<span class="string">"发送消息失败！！！"</span>, exc_info=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 接受到消息时调用</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">on_message</span><span class="params">(self, message)</span>:</span></span><br><span class="line">        logging.info(<span class="string">"获取的消息内容为: &#123;&#125;"</span>.format(message))</span><br><span class="line">        parsed = tornado.escape.json_decode(message)</span><br><span class="line">        self.username = parsed[<span class="string">"username"</span>]</span><br><span class="line">        chat = &#123;</span><br><span class="line">            <span class="string">"id"</span>: str(uuid.uuid4()),</span><br><span class="line">            <span class="string">"body"</span>: parsed[<span class="string">"body"</span>],</span><br><span class="line">            <span class="string">"type"</span>: <span class="string">"message"</span>,</span><br><span class="line">            <span class="string">"client_id"</span>: self.client_id,</span><br><span class="line">            <span class="string">"username"</span>: self.username,</span><br><span class="line">            <span class="string">"datetime"</span>: datetime.datetime.now().strftime(<span class="string">"%Y-%m-%d %H:%M:%S"</span>)</span><br><span class="line">        &#125;</span><br><span class="line">        chat[<span class="string">"html"</span>] = tornado.escape.to_basestring(</span><br><span class="line">            self.render_string(<span class="string">"message.html"</span>, message=chat))</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 更新缓存内容</span></span><br><span class="line">        ChatSocketHandler.update_cache(chat)</span><br><span class="line">        <span class="comment"># 向所有客户端发送消息</span></span><br><span class="line">        ChatSocketHandler.send_updates(chat)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">"__main__"</span>:</span><br><span class="line">    tornado.options.parse_command_line()</span><br><span class="line">    app = Application()</span><br><span class="line">    <span class="comment"># 监听端口</span></span><br><span class="line">    app.listen(options.port)</span><br><span class="line">    tornado.ioloop.IOLoop.current().start()</span><br></pre></td></tr></table></figure><h5 id="4-登录界面"><a href="#4-登录界面" class="headerlink" title="4. 登录界面"></a>4. 登录界面</h5><p>login.html</p><figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&lt;!DOCTYPE <span class="meta-keyword">html</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">html</span> <span class="attr">lang</span>=<span class="string">"en"</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">head</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">meta</span> <span class="attr">charset</span>=<span class="string">"UTF-8"</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">title</span>&gt;</span>用户登录<span class="tag">&lt;/<span class="name">title</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">meta</span> <span class="attr">name</span>=<span class="string">"viewport"</span> <span class="attr">content</span>=<span class="string">"width=device-width, initial-scale=1"</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">link</span> <span class="attr">rel</span>=<span class="string">"stylesheet"</span> <span class="attr">href</span>=<span class="string">"https://cdn.staticfile.org/twitter-bootstrap/4.3.1/css/bootstrap.min.css"</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">script</span> <span class="attr">src</span>=<span class="string">"https://cdn.staticfile.org/jquery/3.2.1/jquery.min.js"</span>&gt;</span><span class="tag">&lt;/<span class="name">script</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">script</span> <span class="attr">src</span>=<span class="string">"https://cdn.staticfile.org/popper.js/1.15.0/umd/popper.min.js"</span>&gt;</span><span class="tag">&lt;/<span class="name">script</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">script</span> <span class="attr">src</span>=<span class="string">"https://cdn.staticfile.org/twitter-bootstrap/4.3.1/js/bootstrap.min.js"</span>&gt;</span><span class="tag">&lt;/<span class="name">script</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">head</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">body</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">div</span> <span class="attr">class</span>=<span class="string">"container"</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">form</span> <span class="attr">method</span>=<span class="string">"get"</span> <span class="attr">action</span>=<span class="string">"/login"</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">div</span> <span class="attr">class</span>=<span class="string">"form-group"</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">label</span> <span class="attr">for</span>=<span class="string">"text"</span>&gt;</span>用户名:<span class="tag">&lt;/<span class="name">label</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">input</span> <span class="attr">type</span>=<span class="string">"text"</span> <span class="attr">class</span>=<span class="string">"form-control"</span> <span class="attr">id</span>=<span class="string">"userName"</span> <span class="attr">name</span>=<span class="string">"userName"</span> <span class="attr">placeholder</span>=<span class="string">"请输入用户名"</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">div</span> <span class="attr">class</span>=<span class="string">"form-group"</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">label</span> <span class="attr">for</span>=<span class="string">"pwd"</span>&gt;</span>密码:<span class="tag">&lt;/<span class="name">label</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">input</span> <span class="attr">type</span>=<span class="string">"password"</span> <span class="attr">class</span>=<span class="string">"form-control"</span> <span class="attr">id</span>=<span class="string">"userPwd"</span> <span class="attr">name</span>=<span class="string">"userPwd"</span> <span class="attr">placeholder</span>=<span class="string">"请输入密码"</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">button</span> <span class="attr">type</span>=<span class="string">"submit"</span> <span class="attr">class</span>=<span class="string">"btn btn-primary"</span>&gt;</span>登录<span class="tag">&lt;/<span class="name">button</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">form</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;/<span class="name">body</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">html</span>&gt;</span></span><br></pre></td></tr></table></figure><h5 id="5-首页"><a href="#5-首页" class="headerlink" title="5. 首页"></a>5. 首页</h5><p>1.index.html</p><figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&lt;!DOCTYPE <span class="meta-keyword">html</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">html</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">head</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">title</span>&gt;</span>首页<span class="tag">&lt;/<span class="name">title</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">meta</span> <span class="attr">charset</span>=<span class="string">"utf-8"</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">meta</span> <span class="attr">name</span>=<span class="string">"viewport"</span> <span class="attr">content</span>=<span class="string">"width=device-width, initial-scale=1"</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">link</span> <span class="attr">rel</span>=<span class="string">"stylesheet"</span> <span class="attr">href</span>=<span class="string">"https://cdn.staticfile.org/twitter-bootstrap/4.3.1/css/bootstrap.min.css"</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">script</span> <span class="attr">src</span>=<span class="string">"https://cdn.staticfile.org/jquery/3.2.1/jquery.min.js"</span>&gt;</span><span class="tag">&lt;/<span class="name">script</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">script</span> <span class="attr">src</span>=<span class="string">"https://cdn.staticfile.org/popper.js/1.15.0/umd/popper.min.js"</span>&gt;</span><span class="tag">&lt;/<span class="name">script</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">script</span> <span class="attr">src</span>=<span class="string">"https://cdn.staticfile.org/twitter-bootstrap/4.3.1/js/bootstrap.min.js"</span>&gt;</span><span class="tag">&lt;/<span class="name">script</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">head</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">body</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">div</span> <span class="attr">class</span>=<span class="string">"container-fluid"</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">div</span> <span class="attr">class</span>=<span class="string">"row"</span> <span class="attr">id</span>=<span class="string">"row"</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">div</span> <span class="attr">class</span>=<span class="string">"col-sm-3"</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">div</span> <span class="attr">id</span>=<span class="string">"users"</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">h3</span>&gt;</span>在线用户:<span class="tag">&lt;/<span class="name">h3</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">ul</span> <span class="attr">id</span>=<span class="string">"user_list"</span>&gt;</span></span><br><span class="line">                    &#123;% for client in clients %&#125;</span><br><span class="line">                    <span class="tag">&lt;<span class="name">li</span> <span class="attr">id</span>=<span class="string">&#123;&#123;</span> <span class="attr">client.client_id</span> &#125;&#125;&gt;</span>&#123;&#123; client.username &#125;&#125;<span class="tag">&lt;/<span class="name">li</span>&gt;</span></span><br><span class="line">                    &#123;% end %&#125;</span><br><span class="line">                <span class="tag">&lt;/<span class="name">ul</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">div</span> <span class="attr">class</span>=<span class="string">"col-sm-9"</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">div</span> <span class="attr">class</span>=<span class="string">"col-sm-12"</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">h3</span>&gt;</span>消息列表:<span class="tag">&lt;/<span class="name">h3</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">div</span> <span class="attr">class</span>=<span class="string">"col-sm-12"</span> <span class="attr">style</span>=<span class="string">"margin-top: 2%"</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">div</span>&gt;</span></span><br><span class="line">                    <span class="tag">&lt;<span class="name">div</span> <span class="attr">id</span>=<span class="string">"inbox"</span> <span class="attr">style</span>=<span class="string">"height: 100px;overflow:auto"</span>&gt;</span></span><br><span class="line">                        &#123;% for message in messages %&#125;</span><br><span class="line">                        &#123;% include "message.html" %&#125;</span><br><span class="line">                        &#123;% end %&#125;</span><br><span class="line">                    <span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line">                    <span class="tag">&lt;<span class="name">div</span> <span class="attr">id</span>=<span class="string">"input"</span>&gt;</span></span><br><span class="line">                        <span class="tag">&lt;<span class="name">form</span> <span class="attr">action</span>=<span class="string">"/"</span> <span class="attr">method</span>=<span class="string">"post"</span> <span class="attr">id</span>=<span class="string">"messageform"</span>&gt;</span></span><br><span class="line">                            <span class="tag">&lt;<span class="name">table</span>&gt;</span></span><br><span class="line">                                <span class="tag">&lt;<span class="name">tr</span>&gt;</span></span><br><span class="line">                                    <span class="tag">&lt;<span class="name">td</span>&gt;</span>用户名:<span class="tag">&lt;/<span class="name">td</span>&gt;</span></span><br><span class="line">                                    <span class="tag">&lt;<span class="name">td</span>&gt;</span><span class="tag">&lt;<span class="name">input</span> <span class="attr">name</span>=<span class="string">"username"</span> <span class="attr">id</span>=<span class="string">"username"</span> <span class="attr">style</span>=<span class="string">"width:100px"</span> <span class="attr">value</span>=<span class="string">"&#123;&#123; username &#125;&#125;"</span></span></span><br><span class="line"><span class="tag">                                               <span class="attr">readonly</span>=<span class="string">"readonly"</span>&gt;</span></span><br><span class="line">                                    <span class="tag">&lt;/<span class="name">td</span>&gt;</span></span><br><span class="line">                                <span class="tag">&lt;/<span class="name">tr</span>&gt;</span></span><br><span class="line"></span><br><span class="line">                                <span class="tag">&lt;<span class="name">tr</span>&gt;</span></span><br><span class="line">                                    <span class="tag">&lt;<span class="name">td</span>&gt;</span>输入消息：<span class="tag">&lt;/<span class="name">td</span>&gt;</span></span><br><span class="line">                                    <span class="tag">&lt;<span class="name">td</span>&gt;</span><span class="tag">&lt;<span class="name">input</span> <span class="attr">name</span>=<span class="string">"body"</span> <span class="attr">id</span>=<span class="string">"message"</span> <span class="attr">style</span>=<span class="string">"width:500px"</span> <span class="attr">type</span>=<span class="string">"text"</span>&gt;</span><span class="tag">&lt;/<span class="name">td</span>&gt;</span></span><br><span class="line">                                <span class="tag">&lt;/<span class="name">tr</span>&gt;</span></span><br><span class="line"></span><br><span class="line">                                <span class="tag">&lt;<span class="name">tr</span>&gt;</span></span><br><span class="line">                                    <span class="tag">&lt;<span class="name">td</span> <span class="attr">style</span>=<span class="string">"padding-left:5px"</span>&gt;</span></span><br><span class="line">                                        <span class="tag">&lt;<span class="name">input</span> <span class="attr">type</span>=<span class="string">"submit"</span> <span class="attr">value</span>=<span class="string">"发送"</span>&gt;</span></span><br><span class="line">                                        <span class="tag">&lt;<span class="name">input</span> <span class="attr">type</span>=<span class="string">"hidden"</span> <span class="attr">name</span>=<span class="string">"next"</span> <span class="attr">value</span>=<span class="string">"&#123;&#123; request.path &#125;&#125;"</span>&gt;</span></span><br><span class="line">                                        &#123;% module xsrf_form_html() %&#125;</span><br><span class="line">                                    <span class="tag">&lt;/<span class="name">td</span>&gt;</span></span><br><span class="line">                                <span class="tag">&lt;/<span class="name">tr</span>&gt;</span></span><br><span class="line">                            <span class="tag">&lt;/<span class="name">table</span>&gt;</span></span><br><span class="line">                        <span class="tag">&lt;/<span class="name">form</span>&gt;</span></span><br><span class="line">                    <span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">script</span> <span class="attr">src</span>=<span class="string">"&#123;&#123; static_url('jquery.min.js') &#125;&#125;"</span> <span class="attr">type</span>=<span class="string">"text/javascript"</span>&gt;</span><span class="tag">&lt;/<span class="name">script</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">script</span> <span class="attr">src</span>=<span class="string">"&#123;&#123; static_url('chat.js') &#125;&#125;"</span> <span class="attr">type</span>=<span class="string">"text/javascript"</span>&gt;</span><span class="tag">&lt;/<span class="name">script</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">script</span> <span class="attr">type</span>=<span class="string">"text/javascript"</span>&gt;</span></span><br><span class="line"><span class="javascript">    <span class="keyword">var</span> div = <span class="built_in">document</span>.getElementById(<span class="string">'inbox'</span>);</span></span><br><span class="line">    div.scrollTop = div.scrollHeight;</span><br><span class="line"><span class="tag">&lt;/<span class="name">script</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">body</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">html</span>&gt;</span></span><br></pre></td></tr></table></figure><ol start="2"><li>message.html<figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">div</span> <span class="attr">class</span>=<span class="string">"message"</span> <span class="attr">id</span>=<span class="string">"m&#123;&#123; message['id'] &#125;&#125;"</span>&gt;</span></span><br><span class="line">    &#123;&#123;message["username"]&#125;&#125; 说：&#123;% module linkify(message["body"]) %&#125;</span><br><span class="line">    (&#123;&#123;message["datetime"]&#125;&#125;)</span><br><span class="line"><span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br></pre></td></tr></table></figure></li></ol><h5 id="6-客户端代码"><a href="#6-客户端代码" class="headerlink" title="6. 客户端代码"></a>6. 客户端代码</h5><p>chat.js</p><figure class="highlight js"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 页面加载完成后调用</span></span><br><span class="line">$(<span class="built_in">document</span>).ready(<span class="function"><span class="keyword">function</span> (<span class="params"></span>) </span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (!<span class="built_in">window</span>.console) <span class="built_in">window</span>.console = &#123;&#125;;</span><br><span class="line">    <span class="keyword">if</span> (!<span class="built_in">window</span>.console.log) <span class="built_in">window</span>.console.log = <span class="function"><span class="keyword">function</span> (<span class="params"></span>) </span>&#123;</span><br><span class="line">    &#125;;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 重新定义提交表单的submit事件</span></span><br><span class="line">    $(<span class="string">"#messageform"</span>).live(<span class="string">"submit"</span>, <span class="function"><span class="keyword">function</span> (<span class="params"></span>) </span>&#123;</span><br><span class="line">        newMessage($(<span class="keyword">this</span>));</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">    &#125;);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 在提交表单时按下回车键自动发送</span></span><br><span class="line">    $(<span class="string">"#messageform"</span>).live(<span class="string">"keypress"</span>, <span class="function"><span class="keyword">function</span> (<span class="params">e</span>) </span>&#123;</span><br><span class="line">        <span class="keyword">if</span> (e.keyCode == <span class="number">13</span>) &#123;</span><br><span class="line">            newMessage($(<span class="keyword">this</span>));</span><br><span class="line">            <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;);</span><br><span class="line">    <span class="comment">// 将页面的焦点聚焦在表单上</span></span><br><span class="line">    $(<span class="string">"#message"</span>).select();</span><br><span class="line">    <span class="comment">// 建立连接</span></span><br><span class="line">    updater.start();</span><br><span class="line">&#125;);</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">newMessage</span>(<span class="params">form</span>) </span>&#123;</span><br><span class="line">    <span class="comment">// 将表单信息封装成json</span></span><br><span class="line">    <span class="keyword">var</span> message = form.formToDict();</span><br><span class="line">    <span class="comment">// console.log("发送的数据： " + JSON.stringify(message));</span></span><br><span class="line">    <span class="comment">// 发送消息</span></span><br><span class="line">    updater.socket.send(<span class="built_in">JSON</span>.stringify(message));</span><br><span class="line">    <span class="keyword">var</span> div = <span class="built_in">document</span>.getElementById(<span class="string">'inbox'</span>);</span><br><span class="line">    div.scrollTop = div.scrollHeight;</span><br><span class="line">    <span class="comment">// 清空表单输入框</span></span><br><span class="line">    form.find(<span class="string">"input[name=body]"</span>).val(<span class="string">""</span>).select();</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 表单信息封装成json</span></span><br><span class="line">jQuery.fn.formToDict = <span class="function"><span class="keyword">function</span> (<span class="params"></span>) </span>&#123;</span><br><span class="line">    <span class="keyword">var</span> fields = <span class="keyword">this</span>.serializeArray();</span><br><span class="line">    <span class="keyword">var</span> json = &#123;&#125;;</span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">var</span> i = <span class="number">0</span>; i &lt; fields.length; i++) &#123;</span><br><span class="line">        json[fields[i].name] = fields[i].value;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">if</span> (json.next) <span class="keyword">delete</span> json.next;</span><br><span class="line">    <span class="keyword">return</span> json;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 添加用户到用户列表</span></span><br><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">add</span>(<span class="params">id, txt</span>) </span>&#123;</span><br><span class="line">    <span class="comment">// 获取ul对象</span></span><br><span class="line">    <span class="keyword">var</span> ul = $(<span class="string">'#user_list'</span>);</span><br><span class="line">    <span class="comment">// 创建li元素，并设置值</span></span><br><span class="line">    <span class="keyword">var</span> li = <span class="built_in">document</span>.createElement(<span class="string">"li"</span>);</span><br><span class="line">    li.innerHTML = txt;</span><br><span class="line">    li.id = id;</span><br><span class="line">    <span class="comment">// 将li添加到ul</span></span><br><span class="line">    ul.append(li);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">del</span>(<span class="params">id</span>) </span>&#123;</span><br><span class="line">    $(<span class="string">'#'</span> + id).remove();</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">var</span> updater = &#123;</span><br><span class="line">    socket: <span class="literal">null</span>,</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 建立websocket连接</span></span><br><span class="line">    start: <span class="function"><span class="keyword">function</span> (<span class="params"></span>) </span>&#123;</span><br><span class="line">        <span class="keyword">var</span> url = <span class="string">"ws://"</span> + location.host + <span class="string">"/chatsocket"</span>;</span><br><span class="line">        updater.socket = <span class="keyword">new</span> WebSocket(url);</span><br><span class="line">        updater.socket.onmessage = <span class="function"><span class="keyword">function</span> (<span class="params">event</span>) </span>&#123;</span><br><span class="line">            updater.showMessage(<span class="built_in">JSON</span>.parse(event.data));</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;,</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 显示信息</span></span><br><span class="line">    showMessage: <span class="function"><span class="keyword">function</span> (<span class="params">message</span>) </span>&#123;</span><br><span class="line">        <span class="comment">// 删除messge的client_id信息</span></span><br><span class="line">        del(message.client_id);</span><br><span class="line">        <span class="comment">// 如果客户端还在线</span></span><br><span class="line">        <span class="keyword">if</span> (message.type != <span class="string">"offline"</span>) &#123;</span><br><span class="line">            add(message.client_id, message.username);</span><br><span class="line">            <span class="keyword">if</span> (message.body == <span class="string">""</span>)</span><br><span class="line">                <span class="keyword">return</span>;</span><br><span class="line">            <span class="keyword">var</span> node = $(message.html);</span><br><span class="line">            <span class="keyword">var</span> existing = $(<span class="string">"#m"</span> + message.id);</span><br><span class="line">            <span class="keyword">if</span> (existing.length &gt; <span class="number">0</span>) <span class="keyword">return</span>;</span><br><span class="line">            node.hide();</span><br><span class="line">            $(<span class="string">"#inbox"</span>).append(node);</span><br><span class="line">            node.slideDown();</span><br><span class="line"></span><br><span class="line">            <span class="keyword">var</span> div = <span class="built_in">document</span>.getElementById(<span class="string">'inbox'</span>);</span><br><span class="line">            div.scrollTop = div.scrollHeight;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h5 id=&quot;1-安装tornado包&quot;&gt;&lt;a href=&quot;#1-安装tornado包&quot; class=&quot;headerlink&quot; title=&quot;1. 安装tornado包&quot;&gt;&lt;/a&gt;1. 安装&lt;code&gt;tornado&lt;/code&gt;包&lt;/h5&gt;&lt;blockquote&gt;
&lt;p&gt;pi
      
    
    </summary>
    
    
      <category term="WebSocket" scheme="http://yoursite.com/categories/WebSocket/"/>
    
    
      <category term="WebSocket" scheme="http://yoursite.com/tags/WebSocket/"/>
    
  </entry>
  
  <entry>
    <title>pytorch-多层神经网络</title>
    <link href="http://yoursite.com/2020/04/09/pytorch-%E5%A4%9A%E5%B1%82%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"/>
    <id>http://yoursite.com/2020/04/09/pytorch-%E5%A4%9A%E5%B1%82%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/</id>
    <published>2020-04-09T04:49:21.000Z</published>
    <updated>2020-04-09T05:01:08.063Z</updated>
    
    <content type="html"><![CDATA[<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> nn</span><br><span class="line"><span class="keyword">from</span> torch.autograd <span class="keyword">import</span> Variable</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line">%matplotlib inline</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br></pre></td><td class="code"><pre><span class="line">data = [(<span class="number">34.62365962451697</span>, <span class="number">78.0246928153624</span>, <span class="number">0.0</span>),</span><br><span class="line"> (<span class="number">30.28671076822607</span>, <span class="number">43.89499752400101</span>, <span class="number">0.0</span>),</span><br><span class="line"> (<span class="number">35.84740876993872</span>, <span class="number">72.90219802708364</span>, <span class="number">0.0</span>),</span><br><span class="line"> (<span class="number">60.18259938620976</span>, <span class="number">86.30855209546826</span>, <span class="number">1.0</span>),</span><br><span class="line"> (<span class="number">79.0327360507101</span>, <span class="number">75.3443764369103</span>, <span class="number">1.0</span>),</span><br><span class="line"> (<span class="number">45.08327747668339</span>, <span class="number">56.3163717815305</span>, <span class="number">0.0</span>),</span><br><span class="line"> (<span class="number">61.10666453684766</span>, <span class="number">96.51142588489624</span>, <span class="number">1.0</span>),</span><br><span class="line"> (<span class="number">75.02474556738889</span>, <span class="number">46.55401354116538</span>, <span class="number">1.0</span>),</span><br><span class="line"> (<span class="number">76.09878670226257</span>, <span class="number">87.42056971926803</span>, <span class="number">1.0</span>),</span><br><span class="line"> (<span class="number">84.43281996120035</span>, <span class="number">43.53339331072109</span>, <span class="number">1.0</span>),</span><br><span class="line"> (<span class="number">95.86155507093572</span>, <span class="number">38.22527805795094</span>, <span class="number">0.0</span>),</span><br><span class="line"> (<span class="number">75.01365838958247</span>, <span class="number">30.60326323428011</span>, <span class="number">0.0</span>),</span><br><span class="line"> (<span class="number">82.30705337399482</span>, <span class="number">76.48196330235604</span>, <span class="number">1.0</span>),</span><br><span class="line"> (<span class="number">69.36458875970939</span>, <span class="number">97.71869196188608</span>, <span class="number">1.0</span>),</span><br><span class="line"> (<span class="number">39.53833914367223</span>, <span class="number">76.03681085115882</span>, <span class="number">0.0</span>),</span><br><span class="line"> (<span class="number">53.9710521485623</span>, <span class="number">89.20735013750205</span>, <span class="number">1.0</span>),</span><br><span class="line"> (<span class="number">69.07014406283025</span>, <span class="number">52.74046973016765</span>, <span class="number">1.0</span>),</span><br><span class="line"> (<span class="number">67.94685547711617</span>, <span class="number">46.67857410673128</span>, <span class="number">0.0</span>),</span><br><span class="line"> (<span class="number">70.66150955499435</span>, <span class="number">92.92713789364831</span>, <span class="number">1.0</span>),</span><br><span class="line"> (<span class="number">76.97878372747498</span>, <span class="number">47.57596364975532</span>, <span class="number">1.0</span>),</span><br><span class="line"> (<span class="number">67.37202754570876</span>, <span class="number">42.83843832029179</span>, <span class="number">0.0</span>),</span><br><span class="line"> (<span class="number">89.6767757507208</span>, <span class="number">65.79936592745237</span>, <span class="number">1.0</span>),</span><br><span class="line"> (<span class="number">50.534788289883</span>, <span class="number">48.85581152764205</span>, <span class="number">0.0</span>),</span><br><span class="line"> (<span class="number">34.21206097786789</span>, <span class="number">44.20952859866288</span>, <span class="number">0.0</span>),</span><br><span class="line"> (<span class="number">77.9240914545704</span>, <span class="number">68.9723599933059</span>, <span class="number">1.0</span>),</span><br><span class="line"> (<span class="number">62.27101367004632</span>, <span class="number">69.95445795447587</span>, <span class="number">1.0</span>),</span><br><span class="line"> (<span class="number">80.1901807509566</span>, <span class="number">44.82162893218353</span>, <span class="number">1.0</span>),</span><br><span class="line"> (<span class="number">93.114388797442</span>, <span class="number">38.80067033713209</span>, <span class="number">0.0</span>),</span><br><span class="line"> (<span class="number">61.83020602312595</span>, <span class="number">50.25610789244621</span>, <span class="number">0.0</span>),</span><br><span class="line"> (<span class="number">38.78580379679423</span>, <span class="number">64.99568095539578</span>, <span class="number">0.0</span>),</span><br><span class="line"> (<span class="number">61.379289447425</span>, <span class="number">72.80788731317097</span>, <span class="number">1.0</span>),</span><br><span class="line"> (<span class="number">85.40451939411645</span>, <span class="number">57.05198397627122</span>, <span class="number">1.0</span>),</span><br><span class="line"> (<span class="number">52.10797973193984</span>, <span class="number">63.12762376881715</span>, <span class="number">0.0</span>),</span><br><span class="line"> (<span class="number">52.04540476831827</span>, <span class="number">69.43286012045222</span>, <span class="number">1.0</span>),</span><br><span class="line"> (<span class="number">40.23689373545111</span>, <span class="number">71.16774802184875</span>, <span class="number">0.0</span>),</span><br><span class="line"> (<span class="number">54.63510555424817</span>, <span class="number">52.21388588061123</span>, <span class="number">0.0</span>),</span><br><span class="line"> (<span class="number">33.91550010906887</span>, <span class="number">98.86943574220611</span>, <span class="number">0.0</span>),</span><br><span class="line"> (<span class="number">64.17698887494485</span>, <span class="number">80.90806058670817</span>, <span class="number">1.0</span>),</span><br><span class="line"> (<span class="number">74.78925295941542</span>, <span class="number">41.57341522824434</span>, <span class="number">0.0</span>),</span><br><span class="line"> (<span class="number">34.1836400264419</span>, <span class="number">75.2377203360134</span>, <span class="number">0.0</span>),</span><br><span class="line"> (<span class="number">83.90239366249155</span>, <span class="number">56.30804621605327</span>, <span class="number">1.0</span>),</span><br><span class="line"> (<span class="number">51.54772026906181</span>, <span class="number">46.85629026349976</span>, <span class="number">0.0</span>),</span><br><span class="line"> (<span class="number">94.44336776917852</span>, <span class="number">65.56892160559052</span>, <span class="number">1.0</span>),</span><br><span class="line"> (<span class="number">82.36875375713919</span>, <span class="number">40.61825515970618</span>, <span class="number">0.0</span>),</span><br><span class="line"> (<span class="number">51.04775177128865</span>, <span class="number">45.82270145776001</span>, <span class="number">0.0</span>),</span><br><span class="line"> (<span class="number">62.22267576120188</span>, <span class="number">52.06099194836679</span>, <span class="number">0.0</span>),</span><br><span class="line"> (<span class="number">77.19303492601364</span>, <span class="number">70.45820000180959</span>, <span class="number">1.0</span>),</span><br><span class="line"> (<span class="number">97.77159928000232</span>, <span class="number">86.7278223300282</span>, <span class="number">1.0</span>),</span><br><span class="line"> (<span class="number">62.07306379667647</span>, <span class="number">96.76882412413983</span>, <span class="number">1.0</span>),</span><br><span class="line"> (<span class="number">91.56497449807442</span>, <span class="number">88.696292545466</span>, <span class="number">1.0</span>),</span><br><span class="line"> (<span class="number">79.94481794066932</span>, <span class="number">74.16311935043758</span>, <span class="number">1.0</span>),</span><br><span class="line"> (<span class="number">99.2725269292572</span>, <span class="number">60.99903099844988</span>, <span class="number">1.0</span>),</span><br><span class="line"> (<span class="number">90.54671411399852</span>, <span class="number">43.39060180650027</span>, <span class="number">1.0</span>),</span><br><span class="line"> (<span class="number">34.52451385320009</span>, <span class="number">60.39634245837173</span>, <span class="number">0.0</span>),</span><br><span class="line"> (<span class="number">50.2864961189907</span>, <span class="number">49.80453881323059</span>, <span class="number">0.0</span>),</span><br><span class="line"> (<span class="number">49.58667721632031</span>, <span class="number">59.80895099453265</span>, <span class="number">0.0</span>),</span><br><span class="line"> (<span class="number">97.64563396007767</span>, <span class="number">68.86157272420604</span>, <span class="number">1.0</span>),</span><br><span class="line"> (<span class="number">32.57720016809309</span>, <span class="number">95.59854761387875</span>, <span class="number">0.0</span>),</span><br><span class="line"> (<span class="number">74.24869136721598</span>, <span class="number">69.82457122657193</span>, <span class="number">1.0</span>),</span><br><span class="line"> (<span class="number">71.7964620586338</span>, <span class="number">78.45356224515052</span>, <span class="number">1.0</span>),</span><br><span class="line"> (<span class="number">75.3956114656803</span>, <span class="number">85.75993667331619</span>, <span class="number">1.0</span>),</span><br><span class="line"> (<span class="number">35.28611281526193</span>, <span class="number">47.02051394723416</span>, <span class="number">0.0</span>),</span><br><span class="line"> (<span class="number">56.25381749711624</span>, <span class="number">39.26147251058019</span>, <span class="number">0.0</span>),</span><br><span class="line"> (<span class="number">30.05882244669796</span>, <span class="number">49.59297386723685</span>, <span class="number">0.0</span>),</span><br><span class="line"> (<span class="number">44.66826172480893</span>, <span class="number">66.45008614558913</span>, <span class="number">0.0</span>),</span><br><span class="line"> (<span class="number">66.56089447242954</span>, <span class="number">41.09209807936973</span>, <span class="number">0.0</span>),</span><br><span class="line"> (<span class="number">40.45755098375164</span>, <span class="number">97.53518548909936</span>, <span class="number">1.0</span>),</span><br><span class="line"> (<span class="number">49.07256321908844</span>, <span class="number">51.88321182073966</span>, <span class="number">0.0</span>),</span><br><span class="line"> (<span class="number">80.27957401466998</span>, <span class="number">92.11606081344084</span>, <span class="number">1.0</span>),</span><br><span class="line"> (<span class="number">66.74671856944039</span>, <span class="number">60.99139402740988</span>, <span class="number">1.0</span>),</span><br><span class="line"> (<span class="number">32.72283304060323</span>, <span class="number">43.30717306430063</span>, <span class="number">0.0</span>),</span><br><span class="line"> (<span class="number">64.0393204150601</span>, <span class="number">78.03168802018232</span>, <span class="number">1.0</span>),</span><br><span class="line"> (<span class="number">72.34649422579923</span>, <span class="number">96.22759296761404</span>, <span class="number">1.0</span>),</span><br><span class="line"> (<span class="number">60.45788573918959</span>, <span class="number">73.09499809758037</span>, <span class="number">1.0</span>),</span><br><span class="line"> (<span class="number">58.84095621726802</span>, <span class="number">75.85844831279042</span>, <span class="number">1.0</span>),</span><br><span class="line"> (<span class="number">99.82785779692128</span>, <span class="number">72.36925193383885</span>, <span class="number">1.0</span>),</span><br><span class="line"> (<span class="number">47.26426910848174</span>, <span class="number">88.47586499559782</span>, <span class="number">1.0</span>),</span><br><span class="line"> (<span class="number">50.45815980285988</span>, <span class="number">75.80985952982456</span>, <span class="number">1.0</span>),</span><br><span class="line"> (<span class="number">60.45555629271532</span>, <span class="number">42.50840943572217</span>, <span class="number">0.0</span>),</span><br><span class="line"> (<span class="number">82.22666157785568</span>, <span class="number">42.71987853716458</span>, <span class="number">0.0</span>),</span><br><span class="line"> (<span class="number">88.9138964166533</span>, <span class="number">69.80378889835472</span>, <span class="number">1.0</span>),</span><br><span class="line"> (<span class="number">94.83450672430196</span>, <span class="number">45.69430680250754</span>, <span class="number">1.0</span>),</span><br><span class="line"> (<span class="number">67.31925746917527</span>, <span class="number">66.58935317747915</span>, <span class="number">1.0</span>),</span><br><span class="line"> (<span class="number">57.23870631569862</span>, <span class="number">59.51428198012956</span>, <span class="number">1.0</span>),</span><br><span class="line"> (<span class="number">80.36675600171273</span>, <span class="number">90.96014789746954</span>, <span class="number">1.0</span>),</span><br><span class="line"> (<span class="number">68.46852178591112</span>, <span class="number">85.59430710452014</span>, <span class="number">1.0</span>),</span><br><span class="line"> (<span class="number">42.0754545384731</span>, <span class="number">78.84478600148043</span>, <span class="number">0.0</span>),</span><br><span class="line"> (<span class="number">75.47770200533905</span>, <span class="number">90.42453899753964</span>, <span class="number">1.0</span>),</span><br><span class="line"> (<span class="number">78.63542434898018</span>, <span class="number">96.64742716885644</span>, <span class="number">1.0</span>),</span><br><span class="line"> (<span class="number">52.34800398794107</span>, <span class="number">60.76950525602592</span>, <span class="number">0.0</span>),</span><br><span class="line"> (<span class="number">94.09433112516793</span>, <span class="number">77.15910509073893</span>, <span class="number">1.0</span>),</span><br><span class="line"> (<span class="number">90.44855097096364</span>, <span class="number">87.50879176484702</span>, <span class="number">1.0</span>),</span><br><span class="line"> (<span class="number">55.48216114069585</span>, <span class="number">35.57070347228866</span>, <span class="number">0.0</span>),</span><br><span class="line"> (<span class="number">74.49269241843041</span>, <span class="number">84.84513684930135</span>, <span class="number">1.0</span>),</span><br><span class="line"> (<span class="number">89.84580670720979</span>, <span class="number">45.35828361091658</span>, <span class="number">1.0</span>),</span><br><span class="line"> (<span class="number">83.48916274498238</span>, <span class="number">48.38028579728175</span>, <span class="number">1.0</span>),</span><br><span class="line"> (<span class="number">42.2617008099817</span>, <span class="number">87.10385094025457</span>, <span class="number">1.0</span>),</span><br><span class="line"> (<span class="number">99.31500880510394</span>, <span class="number">68.77540947206617</span>, <span class="number">1.0</span>),</span><br><span class="line"> (<span class="number">55.34001756003703</span>, <span class="number">64.9319380069486</span>, <span class="number">1.0</span>),</span><br><span class="line"> (<span class="number">74.77589300092767</span>, <span class="number">89.52981289513276</span>, <span class="number">1.0</span>)]</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 标准化</span></span><br><span class="line">x0_max = max([i[<span class="number">0</span>] <span class="keyword">for</span> i <span class="keyword">in</span> data])</span><br><span class="line">x1_max = max([i[<span class="number">1</span>] <span class="keyword">for</span> i <span class="keyword">in</span> data])</span><br><span class="line">data = [(i[<span class="number">0</span>] / x0_max, i[<span class="number">1</span>] / x1_max, i[<span class="number">2</span>]) <span class="keyword">for</span> i <span class="keyword">in</span> data]</span><br><span class="line"></span><br><span class="line">x0 = list(filter(<span class="keyword">lambda</span> x: x[<span class="number">-1</span>] == <span class="number">0.0</span>, data))</span><br><span class="line">x1 = list(filter(<span class="keyword">lambda</span> x: x[<span class="number">-1</span>] == <span class="number">1.0</span>, data))</span><br><span class="line"></span><br><span class="line">plot_x0 = [i[<span class="number">0</span>] <span class="keyword">for</span> i <span class="keyword">in</span> x0]</span><br><span class="line">plot_y0 = [i[<span class="number">1</span>] <span class="keyword">for</span> i <span class="keyword">in</span> x0]</span><br><span class="line">plot_x1 = [i[<span class="number">0</span>] <span class="keyword">for</span> i <span class="keyword">in</span> x1]</span><br><span class="line">plot_y1 = [i[<span class="number">1</span>] <span class="keyword">for</span> i <span class="keyword">in</span> x1]</span><br><span class="line"></span><br><span class="line">plt.plot(plot_x0, plot_y0, <span class="string">'ro'</span>, label=<span class="string">'x_0'</span>)</span><br><span class="line">plt.plot(plot_x1, plot_y1, <span class="string">'bo'</span>, label=<span class="string">'x_1'</span>)</span><br><span class="line">plt.legend(loc=<span class="string">'best'</span>)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">np_data = np.array(data, dtype=<span class="string">'float32'</span>)</span><br><span class="line">x_data = torch.from_numpy(np_data[:, <span class="number">0</span>:<span class="number">2</span>])</span><br><span class="line">y_data = torch.from_numpy(np_data[:, <span class="number">-1</span>]).unsqueeze(<span class="number">1</span>)</span><br></pre></td></tr></table></figure><h4 id="通过Sequential搭建"><a href="#通过Sequential搭建" class="headerlink" title="通过Sequential搭建"></a>通过Sequential搭建</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">seq_net = nn.Sequential(</span><br><span class="line">    nn.Linear(<span class="number">2</span>, <span class="number">10</span>),</span><br><span class="line">    nn.ReLU(),</span><br><span class="line">    nn.Linear(<span class="number">10</span>, <span class="number">2</span>)</span><br><span class="line">)</span><br><span class="line">seq_net</span><br></pre></td></tr></table></figure><pre><code>Sequential(  (0): Linear(in_features=2, out_features=10, bias=True)  (1): ReLU()  (2): Linear(in_features=10, out_features=2, bias=True))</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 序列模块可以通过索引访问每一层</span></span><br><span class="line">print(seq_net[<span class="number">0</span>])</span><br><span class="line"><span class="comment"># 打印出第一层的权重</span></span><br><span class="line">w0 = seq_net[<span class="number">0</span>].weight</span><br><span class="line">print(w0)</span><br><span class="line"><span class="comment"># 通过 parameters 可以取得模型的参数</span></span><br><span class="line">param = seq_net.parameters()</span><br><span class="line">print(param)</span><br><span class="line"><span class="comment"># 定义优化器</span></span><br><span class="line">optimizer = torch.optim.SGD(seq_net.parameters(), lr=<span class="number">0.02</span>)</span><br></pre></td></tr></table></figure><pre><code>Linear(in_features=2, out_features=10, bias=True)Parameter containing:tensor([[-0.5646,  0.7071],        [ 0.1801,  0.2718],        [-0.2039, -0.6752],        [ 0.4783,  0.2476],        [-0.4736,  0.1862],        [-0.2190,  0.5800],        [-0.6509, -0.2531],        [-0.3308,  0.6637],        [-0.3464, -0.6938],        [-0.5845,  0.3192]], requires_grad=True)&lt;generator object Module.parameters at 0x000001DD8AD4F150&gt;</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">criterion = nn.CrossEntropyLoss()</span><br><span class="line"></span><br><span class="line">x_data = x_data.type(torch.FloatTensor)</span><br><span class="line">y_data = y_data.type(torch.LongTensor).view(<span class="number">100</span>)</span><br><span class="line">x_data.shape, y_data.shape</span><br></pre></td></tr></table></figure><pre><code>(torch.Size([100, 2]), torch.Size([100]))</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line">plt.ion()</span><br><span class="line">plt.show()</span><br><span class="line"></span><br><span class="line">optimizer = torch.optim.Adam(seq_net.parameters(), lr=<span class="number">0.02</span>)</span><br><span class="line">loss_func = torch.nn.CrossEntropyLoss()</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">100</span>):</span><br><span class="line">    out = seq_net(x_data)</span><br><span class="line"></span><br><span class="line">    loss = loss_func(out, y_data)</span><br><span class="line"></span><br><span class="line">    optimizer.zero_grad()   <span class="comment"># 清空上一步的残余更新参数值</span></span><br><span class="line">    loss.backward()         <span class="comment"># 误差反向传播, 计算参数更新值</span></span><br><span class="line">    optimizer.step()        <span class="comment"># 将参数更新值施加到 net 的 parameters 上</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">if</span> i % <span class="number">10</span> == <span class="number">0</span>:</span><br><span class="line">        plt.cla()</span><br><span class="line">        prediction = torch.max(F.softmax(out), <span class="number">1</span>)[<span class="number">1</span>]</span><br><span class="line">        pred_y = prediction.data.numpy().squeeze()</span><br><span class="line">        target_y = y_data.data.numpy()</span><br><span class="line">        plt.subplots_adjust(wspace =<span class="number">0</span>, hspace =<span class="number">0</span>)<span class="comment">#调整子图间距</span></span><br><span class="line">        plt.scatter(x_data.data.numpy()[:, <span class="number">0</span>], x_data.data.numpy()[:, <span class="number">1</span>], c=pred_y, s=<span class="number">100</span>, lw=<span class="number">0</span>, cmap=<span class="string">'YlGn'</span>)</span><br><span class="line">        accuracy = sum(pred_y == target_y) / <span class="number">100.</span></span><br><span class="line">        plt.text(<span class="number">2</span>, <span class="number">1</span>, <span class="string">'Accuracy=&#123;:.2f&#125;, loss&#123;:.6f&#125;'</span>.format(accuracy, loss), fontdict=&#123;<span class="string">'size'</span>: <span class="number">20</span>, <span class="string">'color'</span>:  <span class="string">'red'</span>&#125;)</span><br><span class="line">        plt.pause(<span class="number">0.1</span>)</span><br><span class="line"></span><br><span class="line">plt.ioff()</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><h4 id="通过nn-Module搭建"><a href="#通过nn-Module搭建" class="headerlink" title="通过nn.Module搭建"></a>通过nn.Module搭建</h4><h5 id="相对于Sequential更加灵活"><a href="#相对于Sequential更加灵活" class="headerlink" title="相对于Sequential更加灵活"></a>相对于Sequential更加灵活</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">module_net</span><span class="params">(nn.Module)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, num_input, num_hidden, num_output)</span>:</span></span><br><span class="line">        super(module_net, self).__init__()</span><br><span class="line">        self.layer1 = nn.Linear(num_input, num_hidden)</span><br><span class="line">        </span><br><span class="line">        self.layer2 = nn.ReLU()</span><br><span class="line">        </span><br><span class="line">        self.layer3 = nn.Linear(num_hidden, num_output)</span><br><span class="line">        </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, x)</span>:</span></span><br><span class="line">        x = self.layer1(x)</span><br><span class="line">        x = self.layer2(x)</span><br><span class="line">        x = self.layer3(x)</span><br><span class="line">        <span class="keyword">return</span> x</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">mo_net = module_net(<span class="number">2</span>, <span class="number">10</span>, <span class="number">2</span>)</span><br><span class="line">mo_net, mo_net.layer1, mo_net.layer1.weight</span><br></pre></td></tr></table></figure><pre><code>(module_net(   (layer1): Linear(in_features=2, out_features=10, bias=True)   (layer2): ReLU()   (layer3): Linear(in_features=10, out_features=2, bias=True) ), Linear(in_features=2, out_features=10, bias=True), Parameter containing: tensor([[-0.0596,  0.5833],         [-0.2053, -0.3198],         [-0.2849,  0.4568],         [ 0.2389,  0.4954],         [ 0.5458, -0.0301],         [-0.5192,  0.1924],         [-0.5884, -0.6907],         [ 0.6217, -0.2638],         [ 0.6625, -0.5638],         [ 0.5429, -0.4078]], requires_grad=True))</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line">plt.ion()</span><br><span class="line">plt.show()</span><br><span class="line"></span><br><span class="line">optimizer = torch.optim.Adam(mo_net.parameters(), lr=<span class="number">0.02</span>)</span><br><span class="line">loss_func = torch.nn.CrossEntropyLoss()</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">100</span>):</span><br><span class="line">    out = mo_net(x_data)</span><br><span class="line"></span><br><span class="line">    loss = loss_func(out, y_data)</span><br><span class="line"></span><br><span class="line">    optimizer.zero_grad()   <span class="comment"># 清空上一步的残余更新参数值</span></span><br><span class="line">    loss.backward()         <span class="comment"># 误差反向传播, 计算参数更新值</span></span><br><span class="line">    optimizer.step()        <span class="comment"># 将参数更新值施加到 net 的 parameters 上</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">if</span> i % <span class="number">10</span> == <span class="number">0</span>:</span><br><span class="line">        plt.cla()</span><br><span class="line">        prediction = torch.max(F.softmax(out), <span class="number">1</span>)[<span class="number">1</span>]</span><br><span class="line">        pred_y = prediction.data.numpy().squeeze()</span><br><span class="line">        target_y = y_data.data.numpy()</span><br><span class="line">        plt.subplots_adjust(wspace =<span class="number">0</span>, hspace =<span class="number">0</span>)<span class="comment">#调整子图间距</span></span><br><span class="line">        plt.scatter(x_data.data.numpy()[:, <span class="number">0</span>], x_data.data.numpy()[:, <span class="number">1</span>], c=pred_y, s=<span class="number">100</span>, lw=<span class="number">0</span>, cmap=<span class="string">'YlGn'</span>)</span><br><span class="line">        accuracy = sum(pred_y == target_y) / <span class="number">100.</span></span><br><span class="line">        plt.text(<span class="number">2</span>, <span class="number">1</span>, <span class="string">'Accuracy=&#123;:.2f&#125;, loss&#123;:.6f&#125;'</span>.format(accuracy, loss), fontdict=&#123;<span class="string">'size'</span>: <span class="number">20</span>, <span class="string">'color'</span>:  <span class="string">'red'</span>&#125;)</span><br><span class="line">        plt.pause(<span class="number">0.1</span>)</span><br><span class="line"></span><br><span class="line">plt.ioff()</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><h4 id="保存模型和参数"><a href="#保存模型和参数" class="headerlink" title="保存模型和参数"></a>保存模型和参数</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 将参数和模型都保存出来</span></span><br><span class="line">torch.save(seq_net, <span class="string">'save_seq_net.pth'</span>)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 读取保存的模型</span></span><br><span class="line">seq_net1 = torch.load(<span class="string">'save_seq_net.pth'</span>)</span><br><span class="line">seq_net1, seq_net1[<span class="number">0</span>].weight</span><br></pre></td></tr></table></figure><pre><code>(Sequential(   (0): Linear(in_features=2, out_features=10, bias=True)   (1): ReLU()   (2): Linear(in_features=10, out_features=2, bias=True) ), Parameter containing: tensor([[-0.7264,  0.5381],         [ 1.4755,  1.6805],         [-0.2039, -0.6752],         [ 1.9221,  1.8080],         [-0.4736,  0.1862],         [-0.4618,  0.3095],         [-0.6509, -0.2531],         [-1.5772, -0.0485],         [-1.0295, -1.3885],         [-0.5845,  0.3192]], requires_grad=True))</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 保存模型参数</span></span><br><span class="line">torch.save(seq_net.state_dict(), <span class="string">'save_seq_net_params.pth'</span>)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">seq_net2 = nn.Sequential(</span><br><span class="line">    nn.Linear(<span class="number">2</span>, <span class="number">10</span>),</span><br><span class="line">    nn.Tanh(),</span><br><span class="line">    nn.Linear(<span class="number">10</span>, <span class="number">2</span>)</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">seq_net2.load_state_dict(torch.load(<span class="string">'save_seq_net_params.pth'</span>))</span><br><span class="line">seq_net2, seq_net2[<span class="number">0</span>].weight</span><br></pre></td></tr></table></figure><pre><code>(Sequential(   (0): Linear(in_features=2, out_features=10, bias=True)   (1): Tanh()   (2): Linear(in_features=10, out_features=2, bias=True) ), Parameter containing: tensor([[-0.7264,  0.5381],         [ 1.4755,  1.6805],         [-0.2039, -0.6752],         [ 1.9221,  1.8080],         [-0.4736,  0.1862],         [-0.4618,  0.3095],         [-0.6509, -0.2531],         [-1.5772, -0.0485],         [-1.0295, -1.3885],         [-0.5845,  0.3192]], requires_grad=True))</code></pre>]]></content>
    
    <summary type="html">
    
      
      
        &lt;figure class=&quot;highlight python&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span clas
      
    
    </summary>
    
    
      <category term="pytorch" scheme="http://yoursite.com/categories/pytorch/"/>
    
    
      <category term="pytorch" scheme="http://yoursite.com/tags/pytorch/"/>
    
  </entry>
  
  <entry>
    <title>pytorch-单层神经网络</title>
    <link href="http://yoursite.com/2020/04/09/pytorch-%E5%8D%95%E5%B1%82%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"/>
    <id>http://yoursite.com/2020/04/09/pytorch-%E5%8D%95%E5%B1%82%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/</id>
    <published>2020-04-09T04:49:15.000Z</published>
    <updated>2020-04-09T05:03:24.751Z</updated>
    
    <content type="html"><![CDATA[<h3 id="1-监督学习与非监督学习的区别"><a href="#1-监督学习与非监督学习的区别" class="headerlink" title="1.监督学习与非监督学习的区别"></a>1.监督学习与非监督学习的区别</h3><p><a href="https://www.zhihu.com/question/27138263/answer/635004780" target="_blank" rel="noopener">https://www.zhihu.com/question/27138263/answer/635004780</a></p><h3 id="2-实现简单的-y-wx-b-模型"><a href="#2-实现简单的-y-wx-b-模型" class="headerlink" title="2.实现简单的 y = wx + b 模型"></a>2.实现简单的 y = wx + b 模型</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> torch.autograd <span class="keyword">import</span> Variable</span><br><span class="line"><span class="keyword">import</span> torch</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">x_train = Variable(torch.linspace(<span class="number">1</span>, <span class="number">10</span>, <span class="number">10</span>), requires_grad=<span class="literal">True</span>)</span><br><span class="line">y_train = Variable(torch.linspace(<span class="number">10</span>, <span class="number">1</span>, <span class="number">10</span>), requires_grad=<span class="literal">True</span>)</span><br><span class="line">x_train, y_train</span><br></pre></td></tr></table></figure><pre><code>(tensor([ 1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10.], requires_grad=True), tensor([10.,  9.,  8.,  7.,  6.,  5.,  4.,  3.,  2.,  1.], requires_grad=True))</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">w = Variable(torch.randn(<span class="number">1</span>), requires_grad=<span class="literal">True</span>)</span><br><span class="line">b = Variable(torch.zeros(<span class="number">1</span>), requires_grad=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">linear_model</span><span class="params">(x)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> w * x + b</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_loss</span><span class="params">(y_, y)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> torch.mean((y_ - y) ** <span class="number">2</span>)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">1000</span>):</span><br><span class="line">    y_ = linear_model(x_train)</span><br><span class="line">    loss = get_loss(y_, y_train)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># w，b梯度归零</span></span><br><span class="line">    <span class="keyword">if</span> i != <span class="number">0</span>:</span><br><span class="line">        w.grad.data.zero_()</span><br><span class="line">        b.grad.data.zero_()</span><br><span class="line">    </span><br><span class="line">    loss.backward()</span><br><span class="line">    <span class="comment"># 更新w</span></span><br><span class="line">    w.data = w.data - <span class="number">1e-2</span> * w.grad.data</span><br><span class="line">    <span class="comment"># 更新b</span></span><br><span class="line">    b.data = b.data - <span class="number">1e-2</span> * b.grad.data</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">if</span> i % <span class="number">200</span> == <span class="number">0</span>:</span><br><span class="line">        print(<span class="string">'epoch: &#123;&#125;, loss: &#123;&#125;'</span>.format(i, loss.data))</span><br></pre></td></tr></table></figure><pre><code>epoch: 0, loss: 43.67679977416992epoch: 200, loss: 4.732393264770508epoch: 400, loss: 0.8790384531021118epoch: 600, loss: 0.16328111290931702epoch: 800, loss: 0.030329588800668716</code></pre><h3 id="3-Logistic回归模型"><a href="#3-Logistic回归模型" class="headerlink" title="3.Logistic回归模型"></a>3.Logistic回归模型</h3><h4 id="返回0-1之间的概率"><a href="#返回0-1之间的概率" class="headerlink" title="返回0-1之间的概率"></a>返回0-1之间的概率</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line">%matplotlib inline</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br></pre></td><td class="code"><pre><span class="line">data = [(<span class="number">34.62365962451697</span>, <span class="number">78.0246928153624</span>, <span class="number">0.0</span>),</span><br><span class="line"> (<span class="number">30.28671076822607</span>, <span class="number">43.89499752400101</span>, <span class="number">0.0</span>),</span><br><span class="line"> (<span class="number">35.84740876993872</span>, <span class="number">72.90219802708364</span>, <span class="number">0.0</span>),</span><br><span class="line"> (<span class="number">60.18259938620976</span>, <span class="number">86.30855209546826</span>, <span class="number">1.0</span>),</span><br><span class="line"> (<span class="number">79.0327360507101</span>, <span class="number">75.3443764369103</span>, <span class="number">1.0</span>),</span><br><span class="line"> (<span class="number">45.08327747668339</span>, <span class="number">56.3163717815305</span>, <span class="number">0.0</span>),</span><br><span class="line"> (<span class="number">61.10666453684766</span>, <span class="number">96.51142588489624</span>, <span class="number">1.0</span>),</span><br><span class="line"> (<span class="number">75.02474556738889</span>, <span class="number">46.55401354116538</span>, <span class="number">1.0</span>),</span><br><span class="line"> (<span class="number">76.09878670226257</span>, <span class="number">87.42056971926803</span>, <span class="number">1.0</span>),</span><br><span class="line"> (<span class="number">84.43281996120035</span>, <span class="number">43.53339331072109</span>, <span class="number">1.0</span>),</span><br><span class="line"> (<span class="number">95.86155507093572</span>, <span class="number">38.22527805795094</span>, <span class="number">0.0</span>),</span><br><span class="line"> (<span class="number">75.01365838958247</span>, <span class="number">30.60326323428011</span>, <span class="number">0.0</span>),</span><br><span class="line"> (<span class="number">82.30705337399482</span>, <span class="number">76.48196330235604</span>, <span class="number">1.0</span>),</span><br><span class="line"> (<span class="number">69.36458875970939</span>, <span class="number">97.71869196188608</span>, <span class="number">1.0</span>),</span><br><span class="line"> (<span class="number">39.53833914367223</span>, <span class="number">76.03681085115882</span>, <span class="number">0.0</span>),</span><br><span class="line"> (<span class="number">53.9710521485623</span>, <span class="number">89.20735013750205</span>, <span class="number">1.0</span>),</span><br><span class="line"> (<span class="number">69.07014406283025</span>, <span class="number">52.74046973016765</span>, <span class="number">1.0</span>),</span><br><span class="line"> (<span class="number">67.94685547711617</span>, <span class="number">46.67857410673128</span>, <span class="number">0.0</span>),</span><br><span class="line"> (<span class="number">70.66150955499435</span>, <span class="number">92.92713789364831</span>, <span class="number">1.0</span>),</span><br><span class="line"> (<span class="number">76.97878372747498</span>, <span class="number">47.57596364975532</span>, <span class="number">1.0</span>),</span><br><span class="line"> (<span class="number">67.37202754570876</span>, <span class="number">42.83843832029179</span>, <span class="number">0.0</span>),</span><br><span class="line"> (<span class="number">89.6767757507208</span>, <span class="number">65.79936592745237</span>, <span class="number">1.0</span>),</span><br><span class="line"> (<span class="number">50.534788289883</span>, <span class="number">48.85581152764205</span>, <span class="number">0.0</span>),</span><br><span class="line"> (<span class="number">34.21206097786789</span>, <span class="number">44.20952859866288</span>, <span class="number">0.0</span>),</span><br><span class="line"> (<span class="number">77.9240914545704</span>, <span class="number">68.9723599933059</span>, <span class="number">1.0</span>),</span><br><span class="line"> (<span class="number">62.27101367004632</span>, <span class="number">69.95445795447587</span>, <span class="number">1.0</span>),</span><br><span class="line"> (<span class="number">80.1901807509566</span>, <span class="number">44.82162893218353</span>, <span class="number">1.0</span>),</span><br><span class="line"> (<span class="number">93.114388797442</span>, <span class="number">38.80067033713209</span>, <span class="number">0.0</span>),</span><br><span class="line"> (<span class="number">61.83020602312595</span>, <span class="number">50.25610789244621</span>, <span class="number">0.0</span>),</span><br><span class="line"> (<span class="number">38.78580379679423</span>, <span class="number">64.99568095539578</span>, <span class="number">0.0</span>),</span><br><span class="line"> (<span class="number">61.379289447425</span>, <span class="number">72.80788731317097</span>, <span class="number">1.0</span>),</span><br><span class="line"> (<span class="number">85.40451939411645</span>, <span class="number">57.05198397627122</span>, <span class="number">1.0</span>),</span><br><span class="line"> (<span class="number">52.10797973193984</span>, <span class="number">63.12762376881715</span>, <span class="number">0.0</span>),</span><br><span class="line"> (<span class="number">52.04540476831827</span>, <span class="number">69.43286012045222</span>, <span class="number">1.0</span>),</span><br><span class="line"> (<span class="number">40.23689373545111</span>, <span class="number">71.16774802184875</span>, <span class="number">0.0</span>),</span><br><span class="line"> (<span class="number">54.63510555424817</span>, <span class="number">52.21388588061123</span>, <span class="number">0.0</span>),</span><br><span class="line"> (<span class="number">33.91550010906887</span>, <span class="number">98.86943574220611</span>, <span class="number">0.0</span>),</span><br><span class="line"> (<span class="number">64.17698887494485</span>, <span class="number">80.90806058670817</span>, <span class="number">1.0</span>),</span><br><span class="line"> (<span class="number">74.78925295941542</span>, <span class="number">41.57341522824434</span>, <span class="number">0.0</span>),</span><br><span class="line"> (<span class="number">34.1836400264419</span>, <span class="number">75.2377203360134</span>, <span class="number">0.0</span>),</span><br><span class="line"> (<span class="number">83.90239366249155</span>, <span class="number">56.30804621605327</span>, <span class="number">1.0</span>),</span><br><span class="line"> (<span class="number">51.54772026906181</span>, <span class="number">46.85629026349976</span>, <span class="number">0.0</span>),</span><br><span class="line"> (<span class="number">94.44336776917852</span>, <span class="number">65.56892160559052</span>, <span class="number">1.0</span>),</span><br><span class="line"> (<span class="number">82.36875375713919</span>, <span class="number">40.61825515970618</span>, <span class="number">0.0</span>),</span><br><span class="line"> (<span class="number">51.04775177128865</span>, <span class="number">45.82270145776001</span>, <span class="number">0.0</span>),</span><br><span class="line"> (<span class="number">62.22267576120188</span>, <span class="number">52.06099194836679</span>, <span class="number">0.0</span>),</span><br><span class="line"> (<span class="number">77.19303492601364</span>, <span class="number">70.45820000180959</span>, <span class="number">1.0</span>),</span><br><span class="line"> (<span class="number">97.77159928000232</span>, <span class="number">86.7278223300282</span>, <span class="number">1.0</span>),</span><br><span class="line"> (<span class="number">62.07306379667647</span>, <span class="number">96.76882412413983</span>, <span class="number">1.0</span>),</span><br><span class="line"> (<span class="number">91.56497449807442</span>, <span class="number">88.696292545466</span>, <span class="number">1.0</span>),</span><br><span class="line"> (<span class="number">79.94481794066932</span>, <span class="number">74.16311935043758</span>, <span class="number">1.0</span>),</span><br><span class="line"> (<span class="number">99.2725269292572</span>, <span class="number">60.99903099844988</span>, <span class="number">1.0</span>),</span><br><span class="line"> (<span class="number">90.54671411399852</span>, <span class="number">43.39060180650027</span>, <span class="number">1.0</span>),</span><br><span class="line"> (<span class="number">34.52451385320009</span>, <span class="number">60.39634245837173</span>, <span class="number">0.0</span>),</span><br><span class="line"> (<span class="number">50.2864961189907</span>, <span class="number">49.80453881323059</span>, <span class="number">0.0</span>),</span><br><span class="line"> (<span class="number">49.58667721632031</span>, <span class="number">59.80895099453265</span>, <span class="number">0.0</span>),</span><br><span class="line"> (<span class="number">97.64563396007767</span>, <span class="number">68.86157272420604</span>, <span class="number">1.0</span>),</span><br><span class="line"> (<span class="number">32.57720016809309</span>, <span class="number">95.59854761387875</span>, <span class="number">0.0</span>),</span><br><span class="line"> (<span class="number">74.24869136721598</span>, <span class="number">69.82457122657193</span>, <span class="number">1.0</span>),</span><br><span class="line"> (<span class="number">71.7964620586338</span>, <span class="number">78.45356224515052</span>, <span class="number">1.0</span>),</span><br><span class="line"> (<span class="number">75.3956114656803</span>, <span class="number">85.75993667331619</span>, <span class="number">1.0</span>),</span><br><span class="line"> (<span class="number">35.28611281526193</span>, <span class="number">47.02051394723416</span>, <span class="number">0.0</span>),</span><br><span class="line"> (<span class="number">56.25381749711624</span>, <span class="number">39.26147251058019</span>, <span class="number">0.0</span>),</span><br><span class="line"> (<span class="number">30.05882244669796</span>, <span class="number">49.59297386723685</span>, <span class="number">0.0</span>),</span><br><span class="line"> (<span class="number">44.66826172480893</span>, <span class="number">66.45008614558913</span>, <span class="number">0.0</span>),</span><br><span class="line"> (<span class="number">66.56089447242954</span>, <span class="number">41.09209807936973</span>, <span class="number">0.0</span>),</span><br><span class="line"> (<span class="number">40.45755098375164</span>, <span class="number">97.53518548909936</span>, <span class="number">1.0</span>),</span><br><span class="line"> (<span class="number">49.07256321908844</span>, <span class="number">51.88321182073966</span>, <span class="number">0.0</span>),</span><br><span class="line"> (<span class="number">80.27957401466998</span>, <span class="number">92.11606081344084</span>, <span class="number">1.0</span>),</span><br><span class="line"> (<span class="number">66.74671856944039</span>, <span class="number">60.99139402740988</span>, <span class="number">1.0</span>),</span><br><span class="line"> (<span class="number">32.72283304060323</span>, <span class="number">43.30717306430063</span>, <span class="number">0.0</span>),</span><br><span class="line"> (<span class="number">64.0393204150601</span>, <span class="number">78.03168802018232</span>, <span class="number">1.0</span>),</span><br><span class="line"> (<span class="number">72.34649422579923</span>, <span class="number">96.22759296761404</span>, <span class="number">1.0</span>),</span><br><span class="line"> (<span class="number">60.45788573918959</span>, <span class="number">73.09499809758037</span>, <span class="number">1.0</span>),</span><br><span class="line"> (<span class="number">58.84095621726802</span>, <span class="number">75.85844831279042</span>, <span class="number">1.0</span>),</span><br><span class="line"> (<span class="number">99.82785779692128</span>, <span class="number">72.36925193383885</span>, <span class="number">1.0</span>),</span><br><span class="line"> (<span class="number">47.26426910848174</span>, <span class="number">88.47586499559782</span>, <span class="number">1.0</span>),</span><br><span class="line"> (<span class="number">50.45815980285988</span>, <span class="number">75.80985952982456</span>, <span class="number">1.0</span>),</span><br><span class="line"> (<span class="number">60.45555629271532</span>, <span class="number">42.50840943572217</span>, <span class="number">0.0</span>),</span><br><span class="line"> (<span class="number">82.22666157785568</span>, <span class="number">42.71987853716458</span>, <span class="number">0.0</span>),</span><br><span class="line"> (<span class="number">88.9138964166533</span>, <span class="number">69.80378889835472</span>, <span class="number">1.0</span>),</span><br><span class="line"> (<span class="number">94.83450672430196</span>, <span class="number">45.69430680250754</span>, <span class="number">1.0</span>),</span><br><span class="line"> (<span class="number">67.31925746917527</span>, <span class="number">66.58935317747915</span>, <span class="number">1.0</span>),</span><br><span class="line"> (<span class="number">57.23870631569862</span>, <span class="number">59.51428198012956</span>, <span class="number">1.0</span>),</span><br><span class="line"> (<span class="number">80.36675600171273</span>, <span class="number">90.96014789746954</span>, <span class="number">1.0</span>),</span><br><span class="line"> (<span class="number">68.46852178591112</span>, <span class="number">85.59430710452014</span>, <span class="number">1.0</span>),</span><br><span class="line"> (<span class="number">42.0754545384731</span>, <span class="number">78.84478600148043</span>, <span class="number">0.0</span>),</span><br><span class="line"> (<span class="number">75.47770200533905</span>, <span class="number">90.42453899753964</span>, <span class="number">1.0</span>),</span><br><span class="line"> (<span class="number">78.63542434898018</span>, <span class="number">96.64742716885644</span>, <span class="number">1.0</span>),</span><br><span class="line"> (<span class="number">52.34800398794107</span>, <span class="number">60.76950525602592</span>, <span class="number">0.0</span>),</span><br><span class="line"> (<span class="number">94.09433112516793</span>, <span class="number">77.15910509073893</span>, <span class="number">1.0</span>),</span><br><span class="line"> (<span class="number">90.44855097096364</span>, <span class="number">87.50879176484702</span>, <span class="number">1.0</span>),</span><br><span class="line"> (<span class="number">55.48216114069585</span>, <span class="number">35.57070347228866</span>, <span class="number">0.0</span>),</span><br><span class="line"> (<span class="number">74.49269241843041</span>, <span class="number">84.84513684930135</span>, <span class="number">1.0</span>),</span><br><span class="line"> (<span class="number">89.84580670720979</span>, <span class="number">45.35828361091658</span>, <span class="number">1.0</span>),</span><br><span class="line"> (<span class="number">83.48916274498238</span>, <span class="number">48.38028579728175</span>, <span class="number">1.0</span>),</span><br><span class="line"> (<span class="number">42.2617008099817</span>, <span class="number">87.10385094025457</span>, <span class="number">1.0</span>),</span><br><span class="line"> (<span class="number">99.31500880510394</span>, <span class="number">68.77540947206617</span>, <span class="number">1.0</span>),</span><br><span class="line"> (<span class="number">55.34001756003703</span>, <span class="number">64.9319380069486</span>, <span class="number">1.0</span>),</span><br><span class="line"> (<span class="number">74.77589300092767</span>, <span class="number">89.52981289513276</span>, <span class="number">1.0</span>)]</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 标准化</span></span><br><span class="line">x0_max = max([i[<span class="number">0</span>] <span class="keyword">for</span> i <span class="keyword">in</span> data])</span><br><span class="line">x1_max = max([i[<span class="number">1</span>] <span class="keyword">for</span> i <span class="keyword">in</span> data])</span><br><span class="line">data = [(i[<span class="number">0</span>] / x0_max, i[<span class="number">1</span>] / x1_max, i[<span class="number">2</span>]) <span class="keyword">for</span> i <span class="keyword">in</span> data]</span><br><span class="line"></span><br><span class="line">x0 = list(filter(<span class="keyword">lambda</span> x: x[<span class="number">-1</span>] == <span class="number">0.0</span>, data))</span><br><span class="line">x1 = list(filter(<span class="keyword">lambda</span> x: x[<span class="number">-1</span>] == <span class="number">1.0</span>, data))</span><br><span class="line"></span><br><span class="line">plot_x0 = [i[<span class="number">0</span>] <span class="keyword">for</span> i <span class="keyword">in</span> x0]</span><br><span class="line">plot_y0 = [i[<span class="number">1</span>] <span class="keyword">for</span> i <span class="keyword">in</span> x0]</span><br><span class="line">plot_x1 = [i[<span class="number">0</span>] <span class="keyword">for</span> i <span class="keyword">in</span> x1]</span><br><span class="line">plot_y1 = [i[<span class="number">1</span>] <span class="keyword">for</span> i <span class="keyword">in</span> x1]</span><br><span class="line"></span><br><span class="line">plt.plot(plot_x0, plot_y0, <span class="string">'ro'</span>, label=<span class="string">'x_0'</span>)</span><br><span class="line">plt.plot(plot_x1, plot_y1, <span class="string">'bo'</span>, label=<span class="string">'x_1'</span>)</span><br><span class="line">plt.legend(loc=<span class="string">'best'</span>)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">np_data = np.array(data, dtype=<span class="string">'float32'</span>)</span><br><span class="line">x_data = torch.from_numpy(np_data[:, <span class="number">0</span>:<span class="number">2</span>])</span><br><span class="line">y_data = torch.from_numpy(np_data[:, <span class="number">-1</span>]).unsqueeze(<span class="number">1</span>)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 值越大，越接近1，反之越接近0</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">sigmoid</span><span class="params">(x)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> <span class="number">1</span> / (<span class="number">1</span> + np.exp(-x))</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">x_data = Variable(x_data)</span><br><span class="line">y_data = Variable(y_data)</span><br><span class="line"></span><br><span class="line">w = Variable(torch.randn(<span class="number">2</span>, <span class="number">1</span>), requires_grad=<span class="literal">True</span>)</span><br><span class="line">b = Variable(torch.zeros(<span class="number">1</span>), requires_grad=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">logistic_regression</span><span class="params">(x)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> torch.sigmoid(torch.mm(x, w) + b)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 初始状态分类结果</span></span><br><span class="line">w0 = w[<span class="number">0</span>].data[<span class="number">0</span>]</span><br><span class="line">w1 = w[<span class="number">1</span>].data[<span class="number">0</span>]</span><br><span class="line">b0 = b.data[<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line">plot_x = np.arange(<span class="number">0.2</span>, <span class="number">1</span>, <span class="number">0.01</span>)</span><br><span class="line">_plot_x = torch.from_numpy(plot_x)</span><br><span class="line"></span><br><span class="line">_plot_y = (-w0 * _plot_x - b0) / w1</span><br><span class="line">plot_y = _plot_y.numpy()</span><br><span class="line"></span><br><span class="line">plt.plot(plot_x, plot_y, <span class="string">'g'</span>, label=<span class="string">'line1'</span>)</span><br><span class="line">plt.plot(plot_x0, plot_y0, <span class="string">'ro'</span>, label=<span class="string">'x_0'</span>)</span><br><span class="line">plt.plot(plot_x1, plot_y1, <span class="string">'bo'</span>, label=<span class="string">'x_1'</span>)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"> <span class="comment"># 计算loss</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">binary_loss</span><span class="params">(y_pred, y)</span>:</span></span><br><span class="line">    logits = (y * y_pred.clamp(<span class="number">1e-12</span>).log() + (<span class="number">1</span> - y) * (<span class="number">1</span> - y_pred).clamp(<span class="number">1e-12</span>).log()).mean()</span><br><span class="line">    <span class="keyword">return</span> -logits</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">y_pred = logistic_regression(x_data)</span><br><span class="line">loss = binary_loss(y_pred, y_data)</span><br><span class="line">print(<span class="string">"first: "</span>, loss)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 自动求导并更新参数</span></span><br><span class="line">loss.backward()</span><br><span class="line">w.data = w.data - <span class="number">0.1</span> * w.grad.data</span><br><span class="line">b.data = b.data - <span class="number">0.1</span> * b.grad.data</span><br><span class="line"></span><br><span class="line"><span class="comment"># 算出一次更新之后的loss</span></span><br><span class="line">y_pred = logistic_regression(x_data)</span><br><span class="line">loss = binary_loss(y_pred, y_data)</span><br><span class="line">print(<span class="string">"second: "</span>, loss)</span><br></pre></td></tr></table></figure><pre><code>first:  tensor(0.7332, grad_fn=&lt;NegBackward&gt;)second:  tensor(0.7268, grad_fn=&lt;NegBackward&gt;)</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 使用 torch.optim 更新参数</span></span><br><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> nn</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"></span><br><span class="line">w = nn.Parameter(torch.randn(<span class="number">2</span>, <span class="number">1</span>))</span><br><span class="line">b = nn.Parameter(torch.zeros(<span class="number">1</span>))</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">logistic_regression</span><span class="params">(x)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> F.sigmoid(torch.mm(x, w) + b)</span><br><span class="line"></span><br><span class="line">optimizer = torch.optim.SGD([w, b], lr=<span class="number">1.</span>)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 进行 1000 次更新</span></span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"></span><br><span class="line">start = time.time()</span><br><span class="line"><span class="keyword">for</span> e <span class="keyword">in</span> range(<span class="number">1000</span>):</span><br><span class="line">    <span class="comment"># 前向传播</span></span><br><span class="line">    y_pred = logistic_regression(x_data)</span><br><span class="line">    loss = binary_loss(y_pred, y_data) <span class="comment"># 计算 loss</span></span><br><span class="line">    <span class="comment"># 反向传播</span></span><br><span class="line">    optimizer.zero_grad() <span class="comment"># 使用优化器将梯度归 0</span></span><br><span class="line">    loss.backward()</span><br><span class="line">    optimizer.step() <span class="comment"># 使用优化器来更新参数</span></span><br><span class="line">    <span class="comment"># 计算正确率</span></span><br><span class="line">    mask = y_pred.ge(<span class="number">0.5</span>).float()</span><br><span class="line">    acc = (mask == y_data).sum().item() / y_data.shape[<span class="number">0</span>]</span><br><span class="line">    <span class="keyword">if</span> (e + <span class="number">1</span>) % <span class="number">200</span> == <span class="number">0</span>:</span><br><span class="line">        print(<span class="string">'epoch: &#123;&#125;, Loss: &#123;:.5f&#125;, Acc: &#123;:.5f&#125;'</span>.format(e+<span class="number">1</span>, loss.item(), acc))</span><br><span class="line">during = time.time() - start</span><br><span class="line">print()</span><br><span class="line">print(<span class="string">'During Time: &#123;:.3f&#125; s'</span>.format(during))</span><br></pre></td></tr></table></figure><pre><code>G:\Anaconda\envs\pytorch\lib\site-packages\torch\nn\functional.py:1386: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.  warnings.warn(&quot;nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.&quot;)epoch: 200, Loss: 0.39108, Acc: 0.92000epoch: 400, Loss: 0.32230, Acc: 0.91000epoch: 600, Loss: 0.28942, Acc: 0.91000epoch: 800, Loss: 0.27000, Acc: 0.91000epoch: 1000, Loss: 0.25711, Acc: 0.90000During Time: 0.590 s</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">w0 = w[<span class="number">0</span>].data[<span class="number">0</span>]</span><br><span class="line">w1 = w[<span class="number">1</span>].data[<span class="number">0</span>]</span><br><span class="line">b0 = b.data[<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line">plot_x = np.arange(<span class="number">0.2</span>, <span class="number">1</span>, <span class="number">0.01</span>)</span><br><span class="line">_plot_x = torch.from_numpy(plot_x)</span><br><span class="line"></span><br><span class="line">_plot_y = (-w0 * _plot_x - b0) / w1</span><br><span class="line">plot_y = _plot_y.numpy()</span><br><span class="line"></span><br><span class="line">plt.plot(plot_x, plot_y, <span class="string">'g'</span>, label=<span class="string">'cutting line'</span>)</span><br><span class="line">plt.plot(plot_x0, plot_y0, <span class="string">'ro'</span>, label=<span class="string">'x_0'</span>)</span><br><span class="line">plt.plot(plot_x1, plot_y1, <span class="string">'bo'</span>, label=<span class="string">'x_1'</span>)</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h3 id=&quot;1-监督学习与非监督学习的区别&quot;&gt;&lt;a href=&quot;#1-监督学习与非监督学习的区别&quot; class=&quot;headerlink&quot; title=&quot;1.监督学习与非监督学习的区别&quot;&gt;&lt;/a&gt;1.监督学习与非监督学习的区别&lt;/h3&gt;&lt;p&gt;&lt;a href=&quot;https://w
      
    
    </summary>
    
    
      <category term="pytorch" scheme="http://yoursite.com/categories/pytorch/"/>
    
    
      <category term="pytorch" scheme="http://yoursite.com/tags/pytorch/"/>
    
  </entry>
  
  <entry>
    <title>pytorch-基础</title>
    <link href="http://yoursite.com/2020/04/09/pytorch-%E5%9F%BA%E7%A1%80/"/>
    <id>http://yoursite.com/2020/04/09/pytorch-%E5%9F%BA%E7%A1%80/</id>
    <published>2020-04-09T04:48:07.000Z</published>
    <updated>2020-04-09T04:50:06.343Z</updated>
    
    <content type="html"><![CDATA[<h3 id="0-编程环境"><a href="#0-编程环境" class="headerlink" title="0.编程环境"></a>0.编程环境</h3><p>pytorch： 1.1.0</p><p>cudatoolkit： 9.0 </p><blockquote><p>安装语句：conda install pytorch torchvision cudatoolkit=9.0</p></blockquote><hr><h3 id="Tensor"><a href="#Tensor" class="headerlink" title="Tensor"></a>Tensor</h3><h4 id="1-创建Tensor"><a href="#1-创建Tensor" class="headerlink" title="1.创建Tensor"></a>1.创建Tensor</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">x1 = torch.Tensor([<span class="number">3</span>, <span class="number">4</span>])</span><br><span class="line">x2 = torch.FloatTensor([<span class="number">4</span>, <span class="number">4</span>])</span><br><span class="line">x3 = torch.randn(<span class="number">3</span>, <span class="number">4</span>)</span><br><span class="line">x1, x2, x3</span><br></pre></td></tr></table></figure><pre><code>(tensor([3., 4.]), tensor([4., 4.]), tensor([[ 1.6399,  1.0582, -0.5927, -1.2985],         [ 0.9312,  0.2299, -0.5940,  1.1357],         [-2.1210, -0.2413,  0.1483,  0.0567]]))</code></pre><h4 id="2-tensor与numpy相互转化"><a href="#2-tensor与numpy相互转化" class="headerlink" title="2.tensor与numpy相互转化"></a>2.tensor与numpy相互转化</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">numpy_tensor = np.random.randn(<span class="number">10</span>, <span class="number">20</span>)</span><br><span class="line"><span class="comment"># 使用from_numpy将numpy转换为tensor</span></span><br><span class="line">numpy_to_pytorch_tensor = torch.from_numpy(numpy_tensor)</span><br><span class="line"><span class="comment"># 使用numpy将tensor转换为numpy</span></span><br><span class="line">pytorch_to_numpy_tensor = numpy_to_pytorch_tensor.numpy()</span><br><span class="line">numpy_to_pytorch_tensor, pytorch_to_numpy_tensor</span><br></pre></td></tr></table></figure><pre><code>(tensor([[-9.2412e-01, -1.6667e+00,  1.3394e+00,  1.9778e-01, -2.9694e-01,           8.4751e-01,  6.4140e-01, -4.3090e-01,  1.7720e+00, -1.8852e+00,           8.3369e-01,  8.8742e-01,  1.7715e+00, -6.0054e-03,  1.5619e+00,          -2.0915e+00, -8.2746e-01,  1.1123e-01, -1.2618e-01,  2.4763e-01],         [-4.5782e-01, -1.8254e+00,  7.1412e-01,  1.5824e+00, -5.0713e-01,           3.8994e-01, -2.0305e-01, -1.8963e-02, -1.4382e+00, -9.3411e-01,          -8.5849e-01,  9.3715e-01, -5.1027e-01,  1.1572e+00, -2.6459e-01,          -1.0785e+00, -6.6564e-01,  2.1692e-01, -4.6277e-01,  8.5931e-01],         [ 6.0922e-01,  9.4794e-01,  2.1098e+00,  6.9449e-01, -2.3971e-01,           2.5584e+00, -1.7604e+00, -1.3253e+00,  4.8066e-01, -8.6905e-01,          -8.9468e-02, -7.1352e-01,  1.8552e+00,  1.0018e+00,  7.4216e-01,          -6.7655e-01, -8.6220e-01,  1.7163e-01, -1.4165e+00, -1.6646e-01],         [ 9.7260e-01,  1.2978e-01,  9.6561e-01,  1.5414e-02, -8.7662e-01,           4.3728e-01,  2.6895e+00, -5.2750e-01, -1.4546e+00,  5.4438e-01,          -6.7887e-02,  2.7071e-01,  5.3887e-01,  2.2135e+00, -9.5517e-03,           5.4388e-01,  7.4464e-01,  9.7403e-01,  2.5108e-01,  7.4396e-01],         [ 3.5210e-02,  1.0553e+00,  1.3343e+00,  2.1891e-01,  5.9012e-01,          -1.9677e+00, -1.3188e+00, -3.4032e-01, -9.5841e-01, -1.3746e+00,          -6.4992e-01, -1.3080e+00, -5.0882e-01, -7.9672e-01,  2.2461e+00,           1.2005e-03,  8.2737e-01,  2.0653e+00, -1.0030e+00,  2.9210e-01],         [ 1.3772e+00, -3.3829e-01,  4.4449e-01,  1.8879e-01, -2.9321e-01,           1.4310e+00, -2.2552e+00,  4.7913e-01,  7.7705e-01, -4.4400e-01,          -1.1134e-01,  2.6779e-01, -1.6378e-01, -2.1376e-01,  4.4889e-02,           4.5546e-01,  1.3229e+00, -1.3188e+00, -1.7017e-01, -1.0302e-02],         [ 4.6297e-01,  2.1189e+00, -2.3435e-02, -7.8211e-02,  1.3628e+00,          -2.0995e-02, -1.6543e+00, -1.3221e+00,  1.2387e+00,  5.3599e-01,           8.7468e-01,  3.4375e-01, -1.8251e+00, -1.2610e+00,  3.2677e-01,          -3.4598e-01,  5.2431e-01, -2.1375e+00,  1.5971e-01,  5.9295e-01],         [-7.2086e-01,  5.0388e-02,  3.7147e-01,  2.1441e-01,  2.7752e-01,          -4.3412e-02, -7.6528e-01,  3.0595e-01, -8.1759e-02, -9.6263e-01,           2.2660e+00, -1.6222e+00, -7.7254e-01, -5.8874e-01, -1.6206e-01,           9.9959e-02, -4.2326e-01, -1.3035e+00,  4.2965e-01, -1.8652e+00],         [ 8.3210e-02, -6.9117e-01, -6.9932e-02,  1.0123e+00,  5.6874e-01,           1.4312e+00,  9.0971e-01, -4.0987e-01,  1.5364e+00, -3.0060e+00,          -1.1676e+00,  7.3152e-01, -5.3547e-01,  6.2758e-01,  7.2038e-01,           3.8058e-01, -1.5071e-01, -4.5310e-01,  1.2311e+00,  1.2751e+00],         [ 1.1279e+00, -6.7724e-01,  1.0866e+00,  1.8366e-01,  1.3432e+00,          -6.0055e-01, -3.6140e-01, -3.7749e-01, -1.7447e+00,  3.3534e-02,           1.1106e+00, -3.1341e-01, -1.0550e+00, -4.3612e-01, -6.1891e-01,          -8.1331e-02, -1.4274e+00, -1.7746e+00, -3.3573e-02,  5.2553e-01]],        dtype=torch.float64), array([[-9.24119145e-01, -1.66668233e+00,  1.33944007e+00,          1.97782246e-01, -2.96938071e-01,  8.47509843e-01,          6.41399494e-01, -4.30896031e-01,  1.77200994e+00,         -1.88519249e+00,  8.33689867e-01,  8.87420023e-01,          1.77151574e+00, -6.00544578e-03,  1.56193118e+00,         -2.09151140e+00, -8.27464434e-01,  1.11227450e-01,         -1.26182897e-01,  2.47629118e-01],        [-4.57822074e-01, -1.82539032e+00,  7.14120077e-01,          1.58241601e+00, -5.07126879e-01,  3.89943202e-01,         -2.03049676e-01, -1.89628927e-02, -1.43817166e+00,         -9.34111184e-01, -8.58486332e-01,  9.37146399e-01,         -5.10274948e-01,  1.15717139e+00, -2.64586075e-01,         -1.07847024e+00, -6.65640023e-01,  2.16919690e-01,         -4.62766316e-01,  8.59308438e-01],        [ 6.09215253e-01,  9.47941689e-01,  2.10980171e+00,          6.94492385e-01, -2.39707574e-01,  2.55837620e+00,         -1.76041514e+00, -1.32534190e+00,  4.80659018e-01,         -8.69046294e-01, -8.94677677e-02, -7.13516299e-01,          1.85517249e+00,  1.00184289e+00,  7.42155646e-01,         -6.76548765e-01, -8.62201892e-01,  1.71625997e-01,         -1.41649249e+00, -1.66462727e-01],        [ 9.72600912e-01,  1.29779120e-01,  9.65611783e-01,          1.54140364e-02, -8.76617897e-01,  4.37278595e-01,          2.68949028e+00, -5.27498252e-01, -1.45456733e+00,          5.44375101e-01, -6.78865782e-02,  2.70708737e-01,          5.38867469e-01,  2.21350448e+00, -9.55167162e-03,          5.43882047e-01,  7.44639047e-01,  9.74030525e-01,          2.51078607e-01,  7.43958315e-01],        [ 3.52098003e-02,  1.05529239e+00,  1.33433528e+00,          2.18913807e-01,  5.90118577e-01, -1.96767854e+00,         -1.31877624e+00, -3.40320056e-01, -9.58410437e-01,         -1.37462721e+00, -6.49921990e-01, -1.30802679e+00,         -5.08818813e-01, -7.96717636e-01,  2.24611300e+00,          1.20051071e-03,  8.27373511e-01,  2.06528393e+00,         -1.00295409e+00,  2.92103662e-01],        [ 1.37715600e+00, -3.38286107e-01,  4.44489389e-01,          1.88794923e-01, -2.93207433e-01,  1.43103010e+00,         -2.25524730e+00,  4.79133747e-01,  7.77053572e-01,         -4.44000931e-01, -1.11336018e-01,  2.67787996e-01,         -1.63778080e-01, -2.13760542e-01,  4.48888788e-02,          4.55459200e-01,  1.32286400e+00, -1.31876985e+00,         -1.70165266e-01, -1.03016587e-02],        [ 4.62968409e-01,  2.11890423e+00, -2.34352451e-02,         -7.82108185e-02,  1.36283128e+00, -2.09948748e-02,         -1.65427713e+00, -1.32207609e+00,  1.23870963e+00,          5.35989217e-01,  8.74677082e-01,  3.43749588e-01,         -1.82509099e+00, -1.26103749e+00,  3.26774242e-01,         -3.45975563e-01,  5.24313247e-01, -2.13753636e+00,          1.59705363e-01,  5.92949967e-01],        [-7.20860330e-01,  5.03881228e-02,  3.71470168e-01,          2.14412630e-01,  2.77515809e-01, -4.34119431e-02,         -7.65284580e-01,  3.05952215e-01, -8.17594492e-02,         -9.62628960e-01,  2.26603806e+00, -1.62217936e+00,         -7.72536688e-01, -5.88738891e-01, -1.62059364e-01,          9.99593039e-02, -4.23262340e-01, -1.30350878e+00,          4.29654099e-01, -1.86524004e+00],        [ 8.32098555e-02, -6.91165828e-01, -6.99324134e-02,          1.01232928e+00,  5.68738691e-01,  1.43121745e+00,          9.09711845e-01, -4.09872272e-01,  1.53643757e+00,         -3.00604923e+00, -1.16761633e+00,  7.31519662e-01,         -5.35470487e-01,  6.27581302e-01,  7.20379815e-01,          3.80580747e-01, -1.50710432e-01, -4.53103275e-01,          1.23112188e+00,  1.27514046e+00],        [ 1.12794012e+00, -6.77241020e-01,  1.08656155e+00,          1.83658105e-01,  1.34320302e+00, -6.00549581e-01,         -3.61398626e-01, -3.77485789e-01, -1.74472608e+00,          3.35344326e-02,  1.11061440e+00, -3.13408496e-01,         -1.05501751e+00, -4.36120518e-01, -6.18910729e-01,         -8.13309625e-02, -1.42736173e+00, -1.77460866e+00,         -3.35733357e-02,  5.25526333e-01]]))</code></pre><h4 id="使用gpu进行运算"><a href="#使用gpu进行运算" class="headerlink" title="使用gpu进行运算"></a>使用gpu进行运算</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">x = torch.randn(<span class="number">3</span>, <span class="number">4</span>)</span><br><span class="line">x</span><br></pre></td></tr></table></figure><pre><code>tensor([[-0.6773,  0.4021,  0.1151, -0.5207],        [-0.3090, -0.7996,  0.4855, -0.7294],        [ 0.2124, -0.8550, -0.3459, -0.1413]])</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">x_gpu = x.cuda(<span class="number">0</span>)</span><br><span class="line">x_gpu</span><br></pre></td></tr></table></figure><pre><code>tensor([[-0.6773,  0.4021,  0.1151, -0.5207],        [-0.3090, -0.7996,  0.4855, -0.7294],        [ 0.2124, -0.8550, -0.3459, -0.1413]], device=&apos;cuda:0&apos;)</code></pre><h4 id="常用矩阵运算"><a href="#常用矩阵运算" class="headerlink" title="常用矩阵运算"></a>常用矩阵运算</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">x1 = torch.ones(<span class="number">3</span>, <span class="number">4</span>)</span><br><span class="line"><span class="comment"># 矩阵和标量运算</span></span><br><span class="line">y1 = x1 + <span class="number">3</span></span><br><span class="line">x1, y1</span><br></pre></td></tr></table></figure><pre><code>(tensor([[1., 1., 1., 1.],         [1., 1., 1., 1.],         [1., 1., 1., 1.]]), tensor([[4., 4., 4., 4.],         [4., 4., 4., 4.],         [4., 4., 4., 4.]]))</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 矩阵和矩阵运算</span></span><br><span class="line">x2 = torch.randn(<span class="number">3</span>, <span class="number">4</span>)</span><br><span class="line">y2 = torch.add(x1, x2)</span><br><span class="line">x1, x2, y2</span><br></pre></td></tr></table></figure><pre><code>(tensor([[1., 1., 1., 1.],         [1., 1., 1., 1.],         [1., 1., 1., 1.]]), tensor([[ 0.9059, -1.7149,  2.1832,  0.3042],         [ 1.6291,  0.7876,  0.4201,  0.7667],         [ 0.0886, -0.0454,  1.3366,  1.2681]]), tensor([[ 1.9059, -0.7149,  3.1832,  1.3042],         [ 2.6291,  1.7876,  1.4201,  1.7667],         [ 1.0886,  0.9546,  2.3366,  2.2681]]))</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 查看tensor的形状</span></span><br><span class="line">y2.shape</span><br></pre></td></tr></table></figure><pre><code>torch.Size([3, 4])</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 矩阵的重新排列</span></span><br><span class="line">y2.view(<span class="number">4</span>, <span class="number">3</span>)</span><br></pre></td></tr></table></figure><pre><code>tensor([[ 1.9059, -0.7149,  3.1832],        [ 1.3042,  2.6291,  1.7876],        [ 1.4201,  1.7667,  1.0886],        [ 0.9546,  2.3366,  2.2681]])</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># unsqueeze表示升维，squeeze表示降维</span></span><br><span class="line">y2 = y2.unsqueeze(<span class="number">1</span>)</span><br><span class="line">y2, y2.shape</span><br></pre></td></tr></table></figure><pre><code>(tensor([[[ 1.9059, -0.7149,  3.1832,  1.3042]],         [[ 2.6291,  1.7876,  1.4201,  1.7667]],         [[ 1.0886,  0.9546,  2.3366,  2.2681]]]), torch.Size([3, 1, 4]))</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">y2 = y2.squeeze(<span class="number">1</span>)</span><br><span class="line">y2, y2.shape</span><br></pre></td></tr></table></figure><pre><code>(tensor([[ 1.9059, -0.7149,  3.1832,  1.3042],         [ 2.6291,  1.7876,  1.4201,  1.7667],         [ 1.0886,  0.9546,  2.3366,  2.2681]]), torch.Size([3, 4]))</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 获取最大值(或最小值)以及下标</span></span><br><span class="line">max_index, max_value = y2.max(dim=<span class="number">1</span>)</span><br><span class="line"><span class="comment"># 或max_index, max_value = torch.max(y2, dim=1)</span></span><br><span class="line">max_index, max_value</span><br></pre></td></tr></table></figure><pre><code>(tensor([3.1832, 2.6291, 2.3366]), tensor([2, 0, 2]))</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 对每列进行求和</span></span><br><span class="line">sum = y2.sum(<span class="number">1</span>)</span><br><span class="line"><span class="comment"># 或sum = torch.sum(y2, dim=1)</span></span><br><span class="line">sum</span><br></pre></td></tr></table></figure><pre><code>tensor([5.6784, 7.6035, 6.6479])</code></pre><h3 id="Variable"><a href="#Variable" class="headerlink" title="Variable"></a>Variable</h3><blockquote><p>存在三个属性：</p><p>1.data表示存放的数据tensor</p><p>2.grad表示梯度</p><p>3.grad_fn表示如何得到Variable</p></blockquote><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> torch.autograd <span class="keyword">import</span> Variable</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">x = Variable(torch.randn(<span class="number">2</span>, <span class="number">3</span>), requires_grad = <span class="literal">True</span>)</span><br><span class="line">y = Variable(torch.randn(<span class="number">2</span>, <span class="number">3</span>), requires_grad = <span class="literal">True</span>)</span><br><span class="line">z = torch.sum(x + y)</span><br><span class="line">z.data</span><br></pre></td></tr></table></figure><pre><code>tensor(-3.7597)</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">z.backward()</span><br><span class="line">x.grad, y.grad, z.data</span><br></pre></td></tr></table></figure><pre><code>(tensor([[1., 1., 1.],         [1., 1., 1.]]), tensor([[1., 1., 1.],         [1., 1., 1.]]), tensor(-3.7597))</code></pre><h3 id="AutoGrad"><a href="#AutoGrad" class="headerlink" title="AutoGrad"></a>AutoGrad</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">x3 = Variable(torch.FloatTensor([<span class="number">2</span>]), requires_grad = <span class="literal">True</span>)</span><br><span class="line"><span class="comment"># x3 = 2，导数为4</span></span><br><span class="line">y = x3 ** <span class="number">2</span></span><br><span class="line">x3, y</span><br></pre></td></tr></table></figure><pre><code>(tensor([2.], requires_grad=True), tensor([4.], grad_fn=&lt;PowBackward0&gt;))</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">y.backward()</span><br><span class="line">x3.grad</span><br></pre></td></tr></table></figure><pre><code>tensor([4.])</code></pre>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h3 id=&quot;0-编程环境&quot;&gt;&lt;a href=&quot;#0-编程环境&quot; class=&quot;headerlink&quot; title=&quot;0.编程环境&quot;&gt;&lt;/a&gt;0.编程环境&lt;/h3&gt;&lt;p&gt;pytorch： 1.1.0&lt;/p&gt;
&lt;p&gt;cudatoolkit： 9.0 &lt;/p&gt;
&lt;blockquot
      
    
    </summary>
    
    
      <category term="pytorch" scheme="http://yoursite.com/categories/pytorch/"/>
    
    
      <category term="pytorch" scheme="http://yoursite.com/tags/pytorch/"/>
    
  </entry>
  
  <entry>
    <title>python-socket通信（udp）</title>
    <link href="http://yoursite.com/2020/04/06/python-socket%E9%80%9A%E4%BF%A1%EF%BC%88udp%EF%BC%89/"/>
    <id>http://yoursite.com/2020/04/06/python-socket%E9%80%9A%E4%BF%A1%EF%BC%88udp%EF%BC%89/</id>
    <published>2020-04-06T03:38:12.000Z</published>
    <updated>2020-04-06T03:40:58.424Z</updated>
    
    <content type="html"><![CDATA[<h5 id="服务端"><a href="#服务端" class="headerlink" title="服务端"></a>服务端</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> socket</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">HOST = <span class="string">'0.0.0.0'</span></span><br><span class="line">PORT = <span class="number">8080</span></span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># AF_INET表示ipv4地址，SOCK_DGRAM表示UDP地址</span></span><br><span class="line">s = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)</span><br><span class="line"><span class="comment"># 绑定ip和端口</span></span><br><span class="line">s.bind((HOST, PORT))</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line">    data, addr = s.recvfrom(<span class="number">1024</span>)</span><br><span class="line">    print(<span class="string">'receive: &#123;&#125; from &#123;&#125;'</span>.format(data, addr))</span><br><span class="line"></span><br><span class="line">s.close()</span><br></pre></td></tr></table></figure><pre><code>receive: b&apos;test udp&apos; from (&apos;127.0.0.1&apos;, 52349)</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure><h5 id="客户端"><a href="#客户端" class="headerlink" title="客户端"></a>客户端</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> socket</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">HOST = <span class="string">'127.0.0.1'</span></span><br><span class="line">PORT = <span class="number">8080</span></span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># AF_INET表示ipv4地址，SOCK_DGRAM表示UDP地址</span></span><br><span class="line">s = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">data = <span class="string">'test udp'</span></span><br><span class="line">s.sendto(data.encode(<span class="string">'utf-8'</span>), (HOST, PORT))</span><br><span class="line">print(<span class="string">'sent: &#123;&#125; to &#123;&#125;:&#123;&#125;'</span>.format(data, HOST, PORT))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 关闭链接</span></span><br><span class="line">s.close()</span><br></pre></td></tr></table></figure><pre><code>sent: test udp to 127.0.0.1:8080</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h5 id=&quot;服务端&quot;&gt;&lt;a href=&quot;#服务端&quot; class=&quot;headerlink&quot; title=&quot;服务端&quot;&gt;&lt;/a&gt;服务端&lt;/h5&gt;&lt;figure class=&quot;highlight python&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;
      
    
    </summary>
    
    
      <category term="python" scheme="http://yoursite.com/categories/python/"/>
    
    
      <category term="python" scheme="http://yoursite.com/tags/python/"/>
    
  </entry>
  
  <entry>
    <title>python-socket通信（tcp）</title>
    <link href="http://yoursite.com/2020/04/06/python-socket%E9%80%9A%E4%BF%A1%EF%BC%88tcp%EF%BC%89/"/>
    <id>http://yoursite.com/2020/04/06/python-socket%E9%80%9A%E4%BF%A1%EF%BC%88tcp%EF%BC%89/</id>
    <published>2020-04-06T03:38:03.000Z</published>
    <updated>2020-04-06T03:39:52.923Z</updated>
    
    <content type="html"><![CDATA[<h5 id="服务端"><a href="#服务端" class="headerlink" title="服务端"></a>服务端</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> socket</span><br><span class="line"><span class="keyword">import</span> datetime</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">HOST = <span class="string">'0.0.0.0'</span></span><br><span class="line">PORT = <span class="number">8080</span></span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># AF_INET表示ipv4地址，SOCK_STREAM表示tcp地址</span></span><br><span class="line">s = socket.socket(socket.AF_INET, socket.SOCK_STREAM)</span><br><span class="line"><span class="comment"># 绑定ip和端口</span></span><br><span class="line">s.bind((HOST, PORT))</span><br><span class="line"><span class="comment"># 监听</span></span><br><span class="line">s.listen(<span class="number">1</span>)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line">    conn, addr = s.accept()</span><br><span class="line">    print(<span class="string">'cllient &#123;&#125; connect'</span>.format(str(addr)))</span><br><span class="line">    dt = datetime.datetime.now()</span><br><span class="line">    message = <span class="string">'current time is &#123;&#125;'</span>.format(str(dt))</span><br><span class="line">    <span class="comment"># 向客户端发送当前时间</span></span><br><span class="line">    conn.send(message.encode(<span class="string">'utf-8'</span>))</span><br><span class="line">    print(<span class="string">'sent:'</span>, message)</span><br><span class="line">    <span class="comment"># 关闭连接</span></span><br><span class="line">    conn.close()</span><br></pre></td></tr></table></figure><pre><code>cllient (&apos;127.0.0.1&apos;, 2968) connectsent: current time is 2020-04-06 10:23:58.975459</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure><h5 id="客户端"><a href="#客户端" class="headerlink" title="客户端"></a>客户端</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> socket</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">HOST = <span class="string">'127.0.0.1'</span></span><br><span class="line">PORT = <span class="number">8080</span></span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># AF_INET表示ipv4地址，SOCK_STREAM表示tcp地址</span></span><br><span class="line">s = socket.socket(socket.AF_INET, socket.SOCK_STREAM)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">s.connect((HOST, PORT))</span><br><span class="line">print(<span class="string">'connect &#123;&#125;, &#123;&#125; '</span>.format(HOST, PORT))</span><br><span class="line"><span class="comment"># 接收数据，接收数据的最大长度为1024</span></span><br><span class="line">data = s.recv(<span class="number">1024</span>)</span><br><span class="line">print(<span class="string">'receive: &#123;&#125;'</span>.format(data))</span><br><span class="line"><span class="comment"># 关闭连接</span></span><br><span class="line">s.close()</span><br></pre></td></tr></table></figure><pre><code>connect 127.0.0.1, 8080 receive: b&apos;current time is 2020-04-06 10:23:58.975459&apos;</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h5 id=&quot;服务端&quot;&gt;&lt;a href=&quot;#服务端&quot; class=&quot;headerlink&quot; title=&quot;服务端&quot;&gt;&lt;/a&gt;服务端&lt;/h5&gt;&lt;figure class=&quot;highlight python&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;
      
    
    </summary>
    
    
      <category term="python" scheme="http://yoursite.com/categories/python/"/>
    
    
      <category term="python" scheme="http://yoursite.com/tags/python/"/>
    
  </entry>
  
  <entry>
    <title>剑指offer-二进制中1的个数（java）</title>
    <link href="http://yoursite.com/2020/04/06/%E5%89%91%E6%8C%87offer-%E4%BA%8C%E8%BF%9B%E5%88%B6%E4%B8%AD1%E7%9A%84%E4%B8%AA%E6%95%B0%EF%BC%88java%EF%BC%89/"/>
    <id>http://yoursite.com/2020/04/06/%E5%89%91%E6%8C%87offer-%E4%BA%8C%E8%BF%9B%E5%88%B6%E4%B8%AD1%E7%9A%84%E4%B8%AA%E6%95%B0%EF%BC%88java%EF%BC%89/</id>
    <published>2020-04-06T03:35:10.000Z</published>
    <updated>2020-04-06T03:35:26.422Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>问题描述：</p><p>输入一个整数，输出该数二进制表示中1的个数。其中负数用补码表示。<br>补码：正数不变，负数是正数的反码+1</p></blockquote><h6 id="解题思路"><a href="#解题思路" class="headerlink" title="解题思路"></a>解题思路</h6><ol><li>将数字转换为二进制表示<code>Integer.toBinaryString(n).toCharArray();</code></li><li>依次判断数组的值是否为1，并计数</li></ol><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Solution</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">NumberOf1</span><span class="params">(<span class="keyword">int</span> n)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">char</span>[] ch a= Integer.toBinaryString(n).toCharArray();</span><br><span class="line">        <span class="keyword">int</span> count = <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">char</span> c : ch) &#123;</span><br><span class="line">            <span class="keyword">if</span> (String.valueOf(c).equals(<span class="string">"1"</span>)) &#123;</span><br><span class="line">                count++;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> count;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;blockquote&gt;
&lt;p&gt;问题描述：&lt;/p&gt;
&lt;p&gt;输入一个整数，输出该数二进制表示中1的个数。其中负数用补码表示。&lt;br&gt;补码：正数不变，负数是正数的反码+1&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h6 id=&quot;解题思路&quot;&gt;&lt;a href=&quot;#解题思路&quot; class=&quot;h
      
    
    </summary>
    
    
      <category term="剑指offer" scheme="http://yoursite.com/categories/%E5%89%91%E6%8C%87offer/"/>
    
    
      <category term="剑指offer" scheme="http://yoursite.com/tags/%E5%89%91%E6%8C%87offer/"/>
    
  </entry>
  
  <entry>
    <title>剑指offer-矩形覆盖（java）</title>
    <link href="http://yoursite.com/2020/04/06/%E5%89%91%E6%8C%87offer-%E7%9F%A9%E5%BD%A2%E8%A6%86%E7%9B%96%EF%BC%88java%EF%BC%89/"/>
    <id>http://yoursite.com/2020/04/06/%E5%89%91%E6%8C%87offer-%E7%9F%A9%E5%BD%A2%E8%A6%86%E7%9B%96%EF%BC%88java%EF%BC%89/</id>
    <published>2020-04-06T03:34:44.000Z</published>
    <updated>2020-04-06T03:34:59.634Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>问题描述：</p><p>我们可以用2<em>1的小矩形横着或者竖着去覆盖更大的矩形。请问用n个2</em>1的小矩形无重叠地覆盖一个2*n的大矩形，总共有多少种方法？</p></blockquote><h6 id="解题思路："><a href="#解题思路：" class="headerlink" title="解题思路："></a>解题思路：</h6><ol><li><code>2*1</code>的矩形在填充时有两种情况，一种是竖着，剩下的区域就变成了<code>（n-1）</code>的问题</li><li>如果矩形横着填充，剩下的区域就变成了<code>（n-2）</code>的问题</li><li>当最后剩下一列时，只有一种填充方法，<code>rectCover[0] = 1</code></li><li>当最后剩下两列时，有两种填充方法，<code>rectCover[1] = 2</code></li></ol><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Solution</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">RectCover</span><span class="params">(<span class="keyword">int</span> target)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span> (target &lt;= <span class="number">2</span>) &#123;</span><br><span class="line">            <span class="keyword">return</span> target;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">int</span>[] rectCover = <span class="keyword">new</span> <span class="keyword">int</span>[target];</span><br><span class="line">        rectCover[<span class="number">0</span>] = <span class="number">1</span>;</span><br><span class="line">        rectCover[<span class="number">1</span>] = <span class="number">2</span>;</span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">2</span>; i &lt; target; i++) &#123;</span><br><span class="line">            rectCover[i] = rectCover[i - <span class="number">1</span>] + rectCover[i - <span class="number">2</span>];</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> rectCover[target - <span class="number">1</span>];</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;blockquote&gt;
&lt;p&gt;问题描述：&lt;/p&gt;
&lt;p&gt;我们可以用2&lt;em&gt;1的小矩形横着或者竖着去覆盖更大的矩形。请问用n个2&lt;/em&gt;1的小矩形无重叠地覆盖一个2*n的大矩形，总共有多少种方法？&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h6 id=&quot;解题思路：&quot;&gt;&lt;a hre
      
    
    </summary>
    
    
      <category term="剑指offer" scheme="http://yoursite.com/categories/%E5%89%91%E6%8C%87offer/"/>
    
    
      <category term="剑指offer" scheme="http://yoursite.com/tags/%E5%89%91%E6%8C%87offer/"/>
    
  </entry>
  
  <entry>
    <title>剑指offer-重建二叉树（java）</title>
    <link href="http://yoursite.com/2020/04/06/%E5%89%91%E6%8C%87offer-%E9%87%8D%E5%BB%BA%E4%BA%8C%E5%8F%89%E6%A0%91%EF%BC%88java%EF%BC%89/"/>
    <id>http://yoursite.com/2020/04/06/%E5%89%91%E6%8C%87offer-%E9%87%8D%E5%BB%BA%E4%BA%8C%E5%8F%89%E6%A0%91%EF%BC%88java%EF%BC%89/</id>
    <published>2020-04-06T03:34:11.000Z</published>
    <updated>2020-04-06T03:34:27.484Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>问题描述：</p><p>输入某二叉树的前序遍历和中序遍历的结果，请重建出该二叉树。假设输入的前序遍历和中序遍历的结果中都不含重复的数字。例如输入前序遍历序列<code>{1,2,4,7,3,5,6,8}</code>和中序遍历序列<code>{4,7,2,1,5,3,8,6}</code>，则重建二叉树并返回。</p></blockquote><h6 id="解题思路"><a href="#解题思路" class="headerlink" title="解题思路"></a>解题思路</h6><ol><li>前序排列的第一个数值即为当前树的根节点，在中序排列中找到这一个数值，可以将中序排列分成两部分，同时也可以根据这两部分的个数将前序排列也分成两部分。这样前序排列的第一部分和中序排列的第一部分就组成了一颗新的树</li><li>递归，每棵树创建一个根节点，在连接上返回的左子树和右子树</li></ol><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * Definition for binary tree</span></span><br><span class="line"><span class="comment"> * public class TreeNode &#123;</span></span><br><span class="line"><span class="comment"> *     int val;</span></span><br><span class="line"><span class="comment"> *     TreeNode left;</span></span><br><span class="line"><span class="comment"> *     TreeNode right;</span></span><br><span class="line"><span class="comment"> *     TreeNode(int x) &#123; val = x; &#125;</span></span><br><span class="line"><span class="comment"> * &#125;</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">import</span> java.util.*;</span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Solution</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> TreeNode <span class="title">reConstructBinaryTree</span><span class="params">(<span class="keyword">int</span>[] pre, <span class="keyword">int</span>[] in)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span> (pre.length == <span class="number">0</span> || in.length == <span class="number">0</span>) &#123;</span><br><span class="line">            <span class="keyword">return</span> <span class="keyword">null</span>;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> (pre.length != in.length) &#123;</span><br><span class="line">            <span class="keyword">return</span> <span class="keyword">null</span>;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">int</span> root = pre[<span class="number">0</span>];</span><br><span class="line">        TreeNode rootNode = <span class="keyword">new</span> TreeNode(root);</span><br><span class="line"></span><br><span class="line">        <span class="keyword">int</span> pos = <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; in.length; i++) &#123;</span><br><span class="line">            <span class="keyword">if</span> (in[i] == root) &#123;</span><br><span class="line">                pos = i;</span><br><span class="line">                <span class="keyword">break</span>;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">int</span>[] inLeft = Arrays.copyOfRange(in, <span class="number">0</span>, pos);</span><br><span class="line">        <span class="keyword">int</span>[] inRight = Arrays.copyOfRange(in, pos + <span class="number">1</span>, in.length);</span><br><span class="line"></span><br><span class="line">        <span class="keyword">int</span>[] preLeft = Arrays.copyOfRange(pre, <span class="number">1</span>, pos + <span class="number">1</span>);</span><br><span class="line">        <span class="keyword">int</span>[] preRight = Arrays.copyOfRange(pre, pos + <span class="number">1</span>, pre.length);</span><br><span class="line"></span><br><span class="line">        TreeNode leftNode = reConstructBinaryTree(preLeft, inLeft);</span><br><span class="line">        TreeNode rightNode = reConstructBinaryTree(preRight, inRight);</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> (leftNode != <span class="keyword">null</span>) &#123;</span><br><span class="line">            rootNode.left = leftNode;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> (rightNode != <span class="keyword">null</span>) &#123;</span><br><span class="line">            rootNode.right = rightNode;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> rootNode;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;blockquote&gt;
&lt;p&gt;问题描述：&lt;/p&gt;
&lt;p&gt;输入某二叉树的前序遍历和中序遍历的结果，请重建出该二叉树。假设输入的前序遍历和中序遍历的结果中都不含重复的数字。例如输入前序遍历序列&lt;code&gt;{1,2,4,7,3,5,6,8}&lt;/code&gt;和中序遍历序列&lt;code&gt;{4
      
    
    </summary>
    
    
      <category term="剑指offer" scheme="http://yoursite.com/categories/%E5%89%91%E6%8C%87offer/"/>
    
    
      <category term="剑指offer" scheme="http://yoursite.com/tags/%E5%89%91%E6%8C%87offer/"/>
    
  </entry>
  
  <entry>
    <title>剑指offer-从尾到头打印链表（java）</title>
    <link href="http://yoursite.com/2020/04/06/%E5%89%91%E6%8C%87offer-%E4%BB%8E%E5%B0%BE%E5%88%B0%E5%A4%B4%E6%89%93%E5%8D%B0%E9%93%BE%E8%A1%A8%EF%BC%88java%EF%BC%89/"/>
    <id>http://yoursite.com/2020/04/06/%E5%89%91%E6%8C%87offer-%E4%BB%8E%E5%B0%BE%E5%88%B0%E5%A4%B4%E6%89%93%E5%8D%B0%E9%93%BE%E8%A1%A8%EF%BC%88java%EF%BC%89/</id>
    <published>2020-04-06T03:33:45.000Z</published>
    <updated>2020-04-06T03:33:58.773Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>问题描述：</p><p>输入一个链表，按链表从尾到头的顺序返回一个<code>ArrayList</code>。</p></blockquote><h6 id="解题思路："><a href="#解题思路：" class="headerlink" title="解题思路："></a>解题思路：</h6><p>因为单链表只能顺序读取，所以创建一个栈存储单链表中的值，在将栈中的值<code>pop</code>到<code>ArrayList</code>中</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment">*    public class ListNode &#123;</span></span><br><span class="line"><span class="comment">*        int val;</span></span><br><span class="line"><span class="comment">*        ListNode next = null;</span></span><br><span class="line"><span class="comment">*</span></span><br><span class="line"><span class="comment">*        ListNode(int val) &#123;</span></span><br><span class="line"><span class="comment">*            this.val = val;</span></span><br><span class="line"><span class="comment">*        &#125;</span></span><br><span class="line"><span class="comment">*    &#125;</span></span><br><span class="line"><span class="comment">*</span></span><br><span class="line"><span class="comment">*/</span></span><br><span class="line"><span class="keyword">import</span> java.util.Stack;</span><br><span class="line"><span class="keyword">import</span> java.util.ArrayList;</span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Solution</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> ArrayList&lt;Integer&gt; <span class="title">printListFromTailToHead</span><span class="params">(ListNode listNode)</span> </span>&#123;</span><br><span class="line">        Stack&lt;Integer&gt; s = <span class="keyword">new</span> Stack&lt;&gt;();</span><br><span class="line">        <span class="keyword">if</span> (listNode != <span class="keyword">null</span>) &#123;</span><br><span class="line">            <span class="keyword">while</span> (listNode.next != <span class="keyword">null</span>) &#123;</span><br><span class="line">                s.push(listNode.val);</span><br><span class="line">                listNode = listNode.next;</span><br><span class="line">            &#125;</span><br><span class="line">            s.push(listNode.val);</span><br><span class="line">        &#125;</span><br><span class="line">        ArrayList&lt;Integer&gt; retList = <span class="keyword">new</span> ArrayList&lt;&gt;();</span><br><span class="line">        <span class="keyword">while</span> (!s.empty()) &#123;</span><br><span class="line">            retList.add(s.pop());</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> retList;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;blockquote&gt;
&lt;p&gt;问题描述：&lt;/p&gt;
&lt;p&gt;输入一个链表，按链表从尾到头的顺序返回一个&lt;code&gt;ArrayList&lt;/code&gt;。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h6 id=&quot;解题思路：&quot;&gt;&lt;a href=&quot;#解题思路：&quot; class=&quot;headerlin
      
    
    </summary>
    
    
      <category term="剑指offer" scheme="http://yoursite.com/categories/%E5%89%91%E6%8C%87offer/"/>
    
    
      <category term="剑指offer" scheme="http://yoursite.com/tags/%E5%89%91%E6%8C%87offer/"/>
    
  </entry>
  
  <entry>
    <title>剑指offer-变态跳台阶（java）</title>
    <link href="http://yoursite.com/2020/04/06/%E5%89%91%E6%8C%87offer-%E5%8F%98%E6%80%81%E8%B7%B3%E5%8F%B0%E9%98%B6%EF%BC%88java%EF%BC%89/"/>
    <id>http://yoursite.com/2020/04/06/%E5%89%91%E6%8C%87offer-%E5%8F%98%E6%80%81%E8%B7%B3%E5%8F%B0%E9%98%B6%EF%BC%88java%EF%BC%89/</id>
    <published>2020-04-06T03:33:18.000Z</published>
    <updated>2020-04-06T03:33:32.434Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>问题描述:</p><p>一只青蛙一次可以跳上1级台阶，也可以跳上2级……它也可以跳上n级。求该青蛙跳上一个n级的台阶总共有多少种跳法。</p></blockquote><h6 id="解题思路："><a href="#解题思路：" class="headerlink" title="解题思路："></a>解题思路：</h6><p>f(n) = f(n-1) + f(n-2) + …… + f(1)<br>f(1) = 1<br>f(2) = 2<br>依次类推<br>f(n) = 2 * f(n-1)</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Solution</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">JumpFloorII</span><span class="params">(<span class="keyword">int</span> target)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">int</span> ret = <span class="number">1</span>;</span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">1</span>; i &lt; target; i++) &#123;</span><br><span class="line">            ret += i;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> ret;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;blockquote&gt;
&lt;p&gt;问题描述:&lt;/p&gt;
&lt;p&gt;一只青蛙一次可以跳上1级台阶，也可以跳上2级……它也可以跳上n级。求该青蛙跳上一个n级的台阶总共有多少种跳法。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h6 id=&quot;解题思路：&quot;&gt;&lt;a href=&quot;#解题思路：&quot; class
      
    
    </summary>
    
    
      <category term="剑指offer" scheme="http://yoursite.com/categories/%E5%89%91%E6%8C%87offer/"/>
    
    
      <category term="剑指offer" scheme="http://yoursite.com/tags/%E5%89%91%E6%8C%87offer/"/>
    
  </entry>
  
  <entry>
    <title>剑指offer-反转链表（java）</title>
    <link href="http://yoursite.com/2020/04/06/%E5%89%91%E6%8C%87offer-%E5%8F%8D%E8%BD%AC%E9%93%BE%E8%A1%A8%EF%BC%88java%EF%BC%89/"/>
    <id>http://yoursite.com/2020/04/06/%E5%89%91%E6%8C%87offer-%E5%8F%8D%E8%BD%AC%E9%93%BE%E8%A1%A8%EF%BC%88java%EF%BC%89/</id>
    <published>2020-04-06T03:32:48.000Z</published>
    <updated>2020-04-06T03:33:04.659Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>问题描述：</p><p>输入一个链表，反转链表后，输出新链表的表头。</p></blockquote><h6 id="解题思路："><a href="#解题思路：" class="headerlink" title="解题思路："></a>解题思路：</h6><ol><li>设置三个指针，第一个指向准备转换节点的前一个节点，一个指向准备转换的节点，最后一个指向准备转换节点的下一个节点；</li><li>循环如果最后一个节点不为空，midNode指向leftNode，leftNode = midNode，midNode = rightNode，rightNode后移一位</li></ol><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">public class ListNode &#123;</span></span><br><span class="line"><span class="comment">    int val;</span></span><br><span class="line"><span class="comment">    ListNode next = null;</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment">    ListNode(int val) &#123;</span></span><br><span class="line"><span class="comment">        this.val = val;</span></span><br><span class="line"><span class="comment">    &#125;</span></span><br><span class="line"><span class="comment">&#125;*/</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Solution</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> ListNode <span class="title">ReverseList</span><span class="params">(ListNode head)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span> (head == <span class="keyword">null</span>)</span><br><span class="line">            <span class="keyword">return</span> <span class="keyword">null</span>;</span><br><span class="line">        <span class="keyword">if</span> (head.next == <span class="keyword">null</span>)</span><br><span class="line">            <span class="keyword">return</span> head;</span><br><span class="line"></span><br><span class="line">        ListNode leftNode = head;</span><br><span class="line">        ListNode midNode = head.next;</span><br><span class="line">        ListNode rightNode = midNode.next;</span><br><span class="line"></span><br><span class="line">        leftNode.next = <span class="keyword">null</span>;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">while</span> (rightNode != <span class="keyword">null</span>) &#123;</span><br><span class="line">            midNode.next = leftNode;</span><br><span class="line">            leftNode = midNode;</span><br><span class="line">            midNode = rightNode;</span><br><span class="line">            rightNode = rightNode.next;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        midNode.next = leftNode;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> midNode;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;blockquote&gt;
&lt;p&gt;问题描述：&lt;/p&gt;
&lt;p&gt;输入一个链表，反转链表后，输出新链表的表头。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h6 id=&quot;解题思路：&quot;&gt;&lt;a href=&quot;#解题思路：&quot; class=&quot;headerlink&quot; title=&quot;解题思路：&quot;&gt;&lt;/a&gt;解
      
    
    </summary>
    
    
      <category term="剑指offer" scheme="http://yoursite.com/categories/%E5%89%91%E6%8C%87offer/"/>
    
    
      <category term="剑指offer" scheme="http://yoursite.com/tags/%E5%89%91%E6%8C%87offer/"/>
    
  </entry>
  
  <entry>
    <title>剑指offer-合并两个排序的链表（java）</title>
    <link href="http://yoursite.com/2020/04/06/%E5%89%91%E6%8C%87offer-%E5%90%88%E5%B9%B6%E4%B8%A4%E4%B8%AA%E6%8E%92%E5%BA%8F%E7%9A%84%E9%93%BE%E8%A1%A8%EF%BC%88java%EF%BC%89/"/>
    <id>http://yoursite.com/2020/04/06/%E5%89%91%E6%8C%87offer-%E5%90%88%E5%B9%B6%E4%B8%A4%E4%B8%AA%E6%8E%92%E5%BA%8F%E7%9A%84%E9%93%BE%E8%A1%A8%EF%BC%88java%EF%BC%89/</id>
    <published>2020-04-06T03:32:10.000Z</published>
    <updated>2020-04-06T03:32:27.759Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>问题描述：</p><p>输入两个单调递增的链表，输出两个链表合成后的链表，当然我们需要合成后的链表满足单调不减规则。</p></blockquote><h6 id="解题思路："><a href="#解题思路：" class="headerlink" title="解题思路："></a>解题思路：</h6><ol><li>首先判断两个链表的头指针哪一个小，就选哪个作为头指针</li><li>循环遍历哪一个链表的值较小，previousNode.next就指向哪一个</li><li>再将没有遍历完的链表接到previousNode的后面</li></ol><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">public class ListNode &#123;</span></span><br><span class="line"><span class="comment">    int val;</span></span><br><span class="line"><span class="comment">    ListNode next = null;</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment">    ListNode(int val) &#123;</span></span><br><span class="line"><span class="comment">        this.val = val;</span></span><br><span class="line"><span class="comment">    &#125;</span></span><br><span class="line"><span class="comment">&#125;*/</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Solution</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> ListNode <span class="title">Merge</span><span class="params">(ListNode list1,ListNode list2)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span> (list1 == <span class="keyword">null</span>)</span><br><span class="line">            <span class="keyword">return</span> list2;</span><br><span class="line">        <span class="keyword">if</span> (list2 == <span class="keyword">null</span>)</span><br><span class="line">            <span class="keyword">return</span> list1;</span><br><span class="line"></span><br><span class="line">        ListNode newHead = <span class="keyword">null</span>;</span><br><span class="line">        <span class="keyword">if</span> (list1.val &lt; list2.val)</span><br><span class="line">            newHead = list1;</span><br><span class="line">        <span class="keyword">else</span></span><br><span class="line">            newHead = list2;</span><br><span class="line"></span><br><span class="line">        ListNode pTmp1 = list1;</span><br><span class="line">        ListNode pTmp2 = list2;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> (newHead == list1) &#123;</span><br><span class="line">            pTmp1 = pTmp1.next;</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            pTmp2 = pTmp2.next;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        ListNode previousNode = newHead;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">while</span> (pTmp1!= <span class="keyword">null</span> &amp;&amp; pTmp2 != <span class="keyword">null</span>)&#123;</span><br><span class="line">            <span class="keyword">if</span> (pTmp1.val &lt; pTmp2.val) &#123;</span><br><span class="line">                previousNode.next = pTmp1;</span><br><span class="line">                previousNode = pTmp1;</span><br><span class="line">                pTmp1 = pTmp1.next;</span><br><span class="line">            &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">                previousNode.next = pTmp2;</span><br><span class="line">                previousNode = pTmp2;</span><br><span class="line">                pTmp2 = pTmp2.next;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> (pTmp1 == <span class="keyword">null</span>)</span><br><span class="line">            previousNode.next = pTmp2;</span><br><span class="line">        <span class="keyword">else</span></span><br><span class="line">            previousNode.next = pTmp1;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> newHead;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;blockquote&gt;
&lt;p&gt;问题描述：&lt;/p&gt;
&lt;p&gt;输入两个单调递增的链表，输出两个链表合成后的链表，当然我们需要合成后的链表满足单调不减规则。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h6 id=&quot;解题思路：&quot;&gt;&lt;a href=&quot;#解题思路：&quot; class=&quot;headerl
      
    
    </summary>
    
    
      <category term="剑指offer" scheme="http://yoursite.com/categories/%E5%89%91%E6%8C%87offer/"/>
    
    
      <category term="剑指offer" scheme="http://yoursite.com/tags/%E5%89%91%E6%8C%87offer/"/>
    
  </entry>
  
  <entry>
    <title>剑指offer-替换空格（java）</title>
    <link href="http://yoursite.com/2020/04/06/%E5%89%91%E6%8C%87offer-%E6%9B%BF%E6%8D%A2%E7%A9%BA%E6%A0%BC%EF%BC%88java%EF%BC%89/"/>
    <id>http://yoursite.com/2020/04/06/%E5%89%91%E6%8C%87offer-%E6%9B%BF%E6%8D%A2%E7%A9%BA%E6%A0%BC%EF%BC%88java%EF%BC%89/</id>
    <published>2020-04-06T03:31:42.000Z</published>
    <updated>2020-04-06T03:31:57.057Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>问题描述：</p><p>请实现一个函数，将一个字符串中的每个空格替换成<code>%20</code>。例如，当字符串为<code>We Are Happy</code>.则经过替换之后的字符串为<code>We%20Are%20Happy</code>。</p></blockquote><h6 id="解题思路"><a href="#解题思路" class="headerlink" title="解题思路"></a>解题思路</h6><ol><li>直接用java的replace方法</li><li>或者自己实现替换方法</li></ol><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Solution</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> String <span class="title">replaceSpace</span><span class="params">(StringBuffer str)</span> </span>&#123;</span><br><span class="line"><span class="comment">//        return str.toString().replace(" ", "%20");</span></span><br><span class="line"></span><br><span class="line">        String[] strs = str.toString().split (<span class="string">""</span>);</span><br><span class="line">        String retStr = <span class="string">""</span>;</span><br><span class="line">        String temp = <span class="string">""</span>;</span><br><span class="line">        <span class="keyword">int</span> strLen = str.toString().length();</span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i = strLen - <span class="number">1</span>; i &gt; -<span class="number">1</span>; --i) &#123;</span><br><span class="line">            temp = strs[i] + <span class="string">""</span>;</span><br><span class="line">            <span class="keyword">if</span> (temp.equals(<span class="string">" "</span>)) &#123;</span><br><span class="line">                retStr += <span class="string">"02%"</span>;</span><br><span class="line">            &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">                retStr += temp;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">new</span> StringBuilder(retStr).reverse().toString();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;blockquote&gt;
&lt;p&gt;问题描述：&lt;/p&gt;
&lt;p&gt;请实现一个函数，将一个字符串中的每个空格替换成&lt;code&gt;%20&lt;/code&gt;。例如，当字符串为&lt;code&gt;We Are Happy&lt;/code&gt;.则经过替换之后的字符串为&lt;code&gt;We%20Are%20Happy&lt;/c
      
    
    </summary>
    
    
      <category term="剑指offer" scheme="http://yoursite.com/categories/%E5%89%91%E6%8C%87offer/"/>
    
    
      <category term="剑指offer" scheme="http://yoursite.com/tags/%E5%89%91%E6%8C%87offer/"/>
    
  </entry>
  
  <entry>
    <title>剑指offer-用两个栈实现队列（java）</title>
    <link href="http://yoursite.com/2020/04/06/%E5%89%91%E6%8C%87offer-%E7%94%A8%E4%B8%A4%E4%B8%AA%E6%A0%88%E5%AE%9E%E7%8E%B0%E9%98%9F%E5%88%97%EF%BC%88java%EF%BC%89/"/>
    <id>http://yoursite.com/2020/04/06/%E5%89%91%E6%8C%87offer-%E7%94%A8%E4%B8%A4%E4%B8%AA%E6%A0%88%E5%AE%9E%E7%8E%B0%E9%98%9F%E5%88%97%EF%BC%88java%EF%BC%89/</id>
    <published>2020-04-06T03:31:14.000Z</published>
    <updated>2020-04-06T03:31:30.284Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>问题描述：</p><p>用两个栈来实现一个队列，完成队列的<code>Push</code>和<code>Pop</code>操作。 队列中的元素为<code>int</code>类型。</p></blockquote><h6 id="解题思路"><a href="#解题思路" class="headerlink" title="解题思路"></a>解题思路</h6><ol><li>队列<code>push</code>时，将值保存在<code>stack1</code>中</li><li>队列<code>pop</code>时，首先将<code>stack2</code>的值<code>pop</code>到<code>stack1</code>中，这样就实现了逆序，此时<code>stack2</code>最顶端的值即为需要弹出的值。<code>stack2</code>弹出后再将<code>stack2</code>的值存放到<code>stack1</code>中</li></ol><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> java.util.Stack;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Solution</span> </span>&#123;</span><br><span class="line">    Stack&lt;Integer&gt; stack1 = <span class="keyword">new</span> Stack&lt;Integer&gt;();</span><br><span class="line">    Stack&lt;Integer&gt; stack2 = <span class="keyword">new</span> Stack&lt;Integer&gt;();</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">push</span><span class="params">(<span class="keyword">int</span> node)</span> </span>&#123;</span><br><span class="line">        stack1.push(node);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">pop</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">while</span> (!stack1.empty()) &#123;</span><br><span class="line">            stack2.push(stack1.pop());</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">int</span> ret = stack2.pop();</span><br><span class="line">        <span class="keyword">while</span> (!stack2.empty())&#123;</span><br><span class="line">            stack1.push(stack2.pop());</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> ret;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;blockquote&gt;
&lt;p&gt;问题描述：&lt;/p&gt;
&lt;p&gt;用两个栈来实现一个队列，完成队列的&lt;code&gt;Push&lt;/code&gt;和&lt;code&gt;Pop&lt;/code&gt;操作。 队列中的元素为&lt;code&gt;int&lt;/code&gt;类型。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h6 id=&quot;解题思
      
    
    </summary>
    
    
      <category term="剑指offer" scheme="http://yoursite.com/categories/%E5%89%91%E6%8C%87offer/"/>
    
    
      <category term="剑指offer" scheme="http://yoursite.com/tags/%E5%89%91%E6%8C%87offer/"/>
    
  </entry>
  
  <entry>
    <title>剑指offer-二维数组中的查找（java）</title>
    <link href="http://yoursite.com/2020/04/06/%E5%89%91%E6%8C%87offer-%E4%BA%8C%E7%BB%B4%E6%95%B0%E7%BB%84%E4%B8%AD%E7%9A%84%E6%9F%A5%E6%89%BE%EF%BC%88java%EF%BC%89/"/>
    <id>http://yoursite.com/2020/04/06/%E5%89%91%E6%8C%87offer-%E4%BA%8C%E7%BB%B4%E6%95%B0%E7%BB%84%E4%B8%AD%E7%9A%84%E6%9F%A5%E6%89%BE%EF%BC%88java%EF%BC%89/</id>
    <published>2020-04-06T03:30:26.000Z</published>
    <updated>2020-04-06T03:30:44.760Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>问题描述：</p><p>在一个二维数组中（每个一维数组的长度相同），每一行都按照从左到右递增的顺序排序，每一列都按照从上到下递增的顺序排序。请完成一个函数，输入这样的一个二维数组和一个整数，判断数组中是否含有该整数。</p></blockquote><h6 id="解题思路"><a href="#解题思路" class="headerlink" title="解题思路"></a>解题思路</h6><p>每次将最右上角的数字跟目标数字进行比较，会产生三种情况：</p><ol><li>最右上角的数字跟目标数字相同，返回<code>true</code></li><li>最右上角的数字大于目标数字，说明目标数字可能存在于该列的左方，<code>col--</code></li><li>最右上角的数字小于目标数字，说明目标数字可能存在于该行的下方，<code>row++</code></li></ol><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Solution</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">Find</span><span class="params">(<span class="keyword">int</span> target, <span class="keyword">int</span>[][] array)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">int</span> row = <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">int</span> col = array[<span class="number">0</span>].length - <span class="number">1</span>;</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">while</span> (row &lt; array.length &amp;&amp; col &gt;= <span class="number">0</span>) &#123;</span><br><span class="line">            <span class="keyword">if</span> (array[row][col] == target) &#123;</span><br><span class="line">                <span class="keyword">return</span> <span class="keyword">true</span>;</span><br><span class="line">            &#125; <span class="keyword">else</span> <span class="keyword">if</span> (array[row][col] &lt; target) &#123;</span><br><span class="line">                row++;</span><br><span class="line">            &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">                col--;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">false</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;blockquote&gt;
&lt;p&gt;问题描述：&lt;/p&gt;
&lt;p&gt;在一个二维数组中（每个一维数组的长度相同），每一行都按照从左到右递增的顺序排序，每一列都按照从上到下递增的顺序排序。请完成一个函数，输入这样的一个二维数组和一个整数，判断数组中是否含有该整数。&lt;/p&gt;
&lt;/blockquo
      
    
    </summary>
    
    
      <category term="剑指offer" scheme="http://yoursite.com/categories/%E5%89%91%E6%8C%87offer/"/>
    
    
      <category term="剑指offer" scheme="http://yoursite.com/tags/%E5%89%91%E6%8C%87offer/"/>
    
  </entry>
  
  <entry>
    <title>剑指offer-旋转数组的最小数字（java）</title>
    <link href="http://yoursite.com/2020/04/06/%E5%89%91%E6%8C%87offer-%E6%97%8B%E8%BD%AC%E6%95%B0%E7%BB%84%E7%9A%84%E6%9C%80%E5%B0%8F%E6%95%B0%E5%AD%97%EF%BC%88java%EF%BC%89/"/>
    <id>http://yoursite.com/2020/04/06/%E5%89%91%E6%8C%87offer-%E6%97%8B%E8%BD%AC%E6%95%B0%E7%BB%84%E7%9A%84%E6%9C%80%E5%B0%8F%E6%95%B0%E5%AD%97%EF%BC%88java%EF%BC%89/</id>
    <published>2020-04-06T03:29:22.000Z</published>
    <updated>2020-04-06T03:30:08.033Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>问题描述：</p><p>把一个数组最开始的若干个元素搬到数组的末尾，我们称之为数组的旋转。<br>输入一个非递减排序的数组的一个旋转，输出旋转数组的最小元素。<br>例如数组{3,4,5,1,2}为{1,2,3,4,5}的一个旋转，该数组的最小值为1。<br>NOTE：给出的所有元素都大于0，若数组大小为0，请返回0。</p></blockquote><h6 id="解题思路："><a href="#解题思路：" class="headerlink" title="解题思路："></a>解题思路：</h6><ol><li>选取中值，比较中值跟最右边值的大小，会有三种情况：</li><li>如果中值等于最右边的值，直接输出</li><li>如果中值大于最右边的值，最小值在中值的右边</li><li>如果中值小于最右边的值，最小值在中值的左边</li></ol><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> java.util.ArrayList;</span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Solution</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">minNumberInRotateArray</span><span class="params">(<span class="keyword">int</span>[] array)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">int</span> left = <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">int</span> right = array.length - <span class="number">1</span>;</span><br><span class="line">        <span class="keyword">if</span> (array.length &lt;= <span class="number">0</span>) &#123;</span><br><span class="line">            <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">while</span> (left &lt;= right) &#123;</span><br><span class="line">            <span class="keyword">int</span> mid = (left + right) &gt;&gt; <span class="number">1</span>;</span><br><span class="line">            <span class="keyword">if</span> (mid == <span class="number">0</span>) &#123;</span><br><span class="line">                <span class="keyword">if</span> (array[mid] &gt; array[mid + <span class="number">1</span>]) &#123;</span><br><span class="line">                    <span class="keyword">return</span> array[mid + <span class="number">1</span>];</span><br><span class="line">                &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">                    <span class="keyword">return</span> array[mid];</span><br><span class="line">                &#125;</span><br><span class="line">            &#125; <span class="keyword">else</span> <span class="keyword">if</span> (array[mid] &lt; array[mid - <span class="number">1</span>]) &#123;</span><br><span class="line">                <span class="keyword">return</span> array[mid];</span><br><span class="line">            &#125; <span class="keyword">else</span> <span class="keyword">if</span> (array[mid] &lt;= array[right]) &#123;</span><br><span class="line">                right = mid - <span class="number">1</span>;</span><br><span class="line">            &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">                left = mid + <span class="number">1</span>;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;blockquote&gt;
&lt;p&gt;问题描述：&lt;/p&gt;
&lt;p&gt;把一个数组最开始的若干个元素搬到数组的末尾，我们称之为数组的旋转。&lt;br&gt;输入一个非递减排序的数组的一个旋转，输出旋转数组的最小元素。&lt;br&gt;例如数组{3,4,5,1,2}为{1,2,3,4,5}的一个旋转，该数组的最小值
      
    
    </summary>
    
    
      <category term="剑指offer" scheme="http://yoursite.com/categories/%E5%89%91%E6%8C%87offer/"/>
    
    
      <category term="剑指offer" scheme="http://yoursite.com/tags/%E5%89%91%E6%8C%87offer/"/>
    
  </entry>
  
  <entry>
    <title>剑指offer-斐波那契数列（java）</title>
    <link href="http://yoursite.com/2020/04/06/%E5%89%91%E6%8C%87offer-%E6%96%90%E6%B3%A2%E9%82%A3%E5%A5%91%E6%95%B0%E5%88%97%EF%BC%88java%EF%BC%89/"/>
    <id>http://yoursite.com/2020/04/06/%E5%89%91%E6%8C%87offer-%E6%96%90%E6%B3%A2%E9%82%A3%E5%A5%91%E6%95%B0%E5%88%97%EF%BC%88java%EF%BC%89/</id>
    <published>2020-04-06T03:28:52.000Z</published>
    <updated>2020-04-06T03:29:08.521Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>问题描述：</p><p>大家都知道斐波那契数列，现在要求输入一个整数n，请你输出斐波那契数列的第n项（从0开始，第0项为0）。<br>n&lt;=39</p></blockquote><h6 id="解题思路："><a href="#解题思路：" class="headerlink" title="解题思路："></a>解题思路：</h6><p>设置一个数组来保存斐波那契数列的值，第一个数值为0，第二个数值为1，依次递推</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Solution</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">Fibonacci</span><span class="params">(<span class="keyword">int</span> n)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">int</span>[] temp = <span class="keyword">new</span> <span class="keyword">int</span>[<span class="number">40</span>];</span><br><span class="line">        temp[<span class="number">0</span>] = <span class="number">0</span>;</span><br><span class="line">        temp[<span class="number">1</span>] = <span class="number">1</span>;</span><br><span class="line">        <span class="keyword">if</span> (n &lt;= <span class="number">1</span>) &#123;</span><br><span class="line">            <span class="keyword">return</span> temp[n];</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">2</span>; i &lt;= n; i++) &#123;</span><br><span class="line">            temp[i] = temp[i - <span class="number">1</span>] + temp[i - <span class="number">2</span>];</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> temp[n];</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;blockquote&gt;
&lt;p&gt;问题描述：&lt;/p&gt;
&lt;p&gt;大家都知道斐波那契数列，现在要求输入一个整数n，请你输出斐波那契数列的第n项（从0开始，第0项为0）。&lt;br&gt;n&amp;lt;=39&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h6 id=&quot;解题思路：&quot;&gt;&lt;a href=&quot;#解题思路
      
    
    </summary>
    
    
      <category term="剑指offer" scheme="http://yoursite.com/categories/%E5%89%91%E6%8C%87offer/"/>
    
    
      <category term="剑指offer" scheme="http://yoursite.com/tags/%E5%89%91%E6%8C%87offer/"/>
    
  </entry>
  
</feed>
